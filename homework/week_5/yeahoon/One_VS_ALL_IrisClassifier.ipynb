{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "One_VS_ALL_IrisClassifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsgaAkLgyLAs",
        "colab_type": "code",
        "outputId": "81d67c7d-e6ad-4b9c-abd8-bf879079c160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "%matplotlib inline\n",
        "!pip install tensorboardcolab\n",
        "import tensorboardcolab\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "je1nCDIAtS2e"
      },
      "source": [
        " ╔══<i><b>&nbsp;Alai-DeepLearning&nbsp;</b></i>══════════════════════════════════╗\n",
        "###  &nbsp;&nbsp; **✎&nbsp;&nbsp;Week 5. machine learning basis**\n",
        "# Homework 2. Multi classification\n",
        "\n",
        "### _Objective_\n",
        "Tensorflow 을 이용해서 One Vs All 전략을 이용해 다중 classification 모델을 생성합니다.\n",
        "\n",
        "아래 순서에 맞게 프로그램을 작성해 주세요.\n",
        "1. Setosa  Vs Versicolour, Virginica 모델 구현\n",
        " - 학습시 Tensorboard 을 이용해 loss 와 accuracy 을 추적해 주세요. \n",
        " - 학습 동안 acc 가 가장 높은 모델을 저장해 주세요.\n",
        "2. Versicolour Vs Setosa, Virginica 모델 구현\n",
        "  - 학습시 Tensorboard 을 이용해 loss 와 accuracy 을 추적해 주세요. \n",
        " - 학습 동안 acc 가 가장 높은 모델을 저장해 주세요.\n",
        "3. Virginica Vs Setosa, Versicolour 모델 구현\n",
        "  - 학습시 Tensorboard 을 이용해 loss 와 accuracy 을 추적해 주세요. \n",
        " - 학습 동안 acc 가 가장 높은 모델을 저장해 주세요.\n",
        "4. 저장된 3개의 모델을 불러온 후 가장 높은 확률이 나오는 값을 선택합니다. <br>\n",
        "가령 아래의 경우 **Versicolour** 을 선택합니다.\n",
        "\n",
        "| class        | probabilty |\n",
        "|--------------|------------|\n",
        "| Setosa       | 0.7        |\n",
        "| Versicolour  | 0.9        |\n",
        "| Virginica    | 0.3        |\n",
        "\n",
        "학습이 끝난후 모든 데이터를 평가한 후 accuracy 을 측정합니다.\n",
        "\n",
        "╚═══════════════════════════════════════════════╝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcK1tZ3V-Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.random.seed(1)    \n",
        "iris = load_iris()\n",
        "\n",
        "xs = iris['data']\n",
        "ys = iris['target']\n",
        "ys_name = iris['target_names']\n",
        "ys_name\n",
        "\n",
        "#standarization\n",
        "xs = (xs - xs.mean(axis=0))/xs.std(axis=0)\n",
        "#print(xs.std(axis=0))\n",
        "#print(xs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXpJeZaEGX5O",
        "colab_type": "code",
        "outputId": "16a37949-1dd5-46a7-ba2e-d2404f074732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "tbc=tensorboardcolab.TensorBoardColab(graph_path='./tensorboard')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://be894bb5.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypPN7jjzya-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier :\n",
        "    def __init__(self, one) :\n",
        "        self.one = one\n",
        "        self.train_acc_ = 0\n",
        "        \n",
        "        #label 만들기\n",
        "        label = np.array(list(map(lambda ys : 1 if ys != one else 0, ys)))\n",
        "        label = np.reshape(label, (-1,1))\n",
        "        #print(label.shape)\n",
        "\n",
        "        con_xs_ys = np.concatenate((xs,label), axis = 1)\n",
        "\n",
        "        #train _ test split\n",
        "        train_df, test_df = train_test_split(con_xs_ys,\n",
        "                                            stratify=con_xs_ys[:,-1],\n",
        "                                            train_size=0.8)\n",
        "        xs_train = train_df[:,:-1]\n",
        "        #print(xs_train.shape)\n",
        "        label_train = train_df[:,-1]\n",
        "        label_train = np.reshape(label_train, (-1,1))\n",
        "\n",
        "        xs_test = test_df[:,:-1]\n",
        "        label_test = test_df[:,-1]\n",
        "        label_test = np.reshape(label_test, (-1,1))\n",
        "\n",
        "        graph = tf.Graph()\n",
        "        with graph.as_default() :\n",
        "            #model 정의\n",
        "            xs_holder = tf.placeholder(dtype=tf.float32, shape = [None, 4])\n",
        "            ys_holder = tf.placeholder(dtype=tf.float32, shape = [None,1])\n",
        "            w = tf.Variable(tf.random.normal(shape=[4,1], mean = 0.0, stddev = 0.1), dtype= tf.float32)\n",
        "            bias = tf.Variable(tf.random.normal(shape = [1], mean = 0.0, stddev = 0.1), dtype = tf.float32)\n",
        "\n",
        "            z = tf.add(tf.matmul(xs_holder,w),bias)\n",
        "\n",
        "            prob = 1/(1 + tf.exp(-z))\n",
        "\n",
        "            w_del = tf.reduce_mean((prob - ys_holder) * xs_holder, axis = 0)\n",
        "            w_del_reshape = tf.reshape(w_del, shape = (-1,1))\n",
        "            w_new = w - (0.01 * w_del_reshape)\n",
        "            asig_w = tf.assign(w, w_new)\n",
        "\n",
        "            b_del = tf.reduce_mean((prob - ys_holder), axis=0)\n",
        "            #b_del_reshape = tf.reshape(b_del, shape = (-1))\n",
        "            b_new = bias - (0.01 * b_del)\n",
        "            asig_b = tf.assign(bias, b_new)\n",
        "\n",
        "            train = tf.group([asig_w, asig_b])\n",
        "\n",
        "            cross_entro = -(tf.reduce_mean(ys_holder*tf.log(prob) + (1-ys_holder)*tf.log(1-prob)))\n",
        "            tf.summary.scalar(name = 'loss_sc' , tensor = cross_entro)\n",
        "\n",
        "            cut_val = tf.constant(0.5, dtype=tf.float32)\n",
        "            g_e = tf.greater_equal(prob, cut_val)\n",
        "            one = tf.ones(tf.shape(g_e),dtype = tf.float32)\n",
        "            zeros = tf.zeros(tf.shape(g_e), dtype = tf.float32)\n",
        "            cut_res = tf.where(g_e, one, zeros)\n",
        "            equ = tf.where(tf.equal(cut_res, ys_holder), one, zeros)\n",
        "            #print(equ.get_shape())\n",
        "            acc = tf.reduce_mean(equ)\n",
        "            #print(tf.shape(acc))\n",
        "            tf.summary.scalar(name = 'acc_sc', tensor = acc)\n",
        "\n",
        "            merge = tf.summary.merge_all()\n",
        "            with tf.Session() as sess :\n",
        "                sess.run(tf.global_variables_initializer())\n",
        "                writer = tf.summary.FileWriter(logdir='./tensorboard', graph = sess.graph)\n",
        "\n",
        "                for i in range(100) :\n",
        "                    _, merge_, loss_, acc_ = sess.run([train, merge, cross_entro, acc],\n",
        "                                                      feed_dict = {xs_holder : xs_train,\n",
        "                                                                   ys_holder : label_train})\n",
        "\n",
        "                    #acc_test = sess.run([acc], feed_dict = {xs_holder : xs_test, ys_holder : label_test})\n",
        "\n",
        "                    writer.add_summary(merge_, i)\n",
        "                    #print(\"step : {}\".format(i))\n",
        "                    #print(\"train_acc : {}\".format(acc_))\n",
        "                    #print(\"train_loss : {}\".format(loss_))\n",
        "                    #print(\"test_acc : {}\".format(acc_test))\n",
        "                    #print(\"-------------------\")\n",
        "                saver = tf.train.Saver()\n",
        "                saver.save(sess, './tmp/model{}'.format(self.one))    \n",
        "                self.train_acc_ = acc_\n",
        "        \n",
        "    def print_acc(self):\n",
        "        print(self.train_acc_)\n",
        "        return self.train_acc_\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrGHNB6JzNr9",
        "colab_type": "code",
        "outputId": "62f5f85e-ce94-4460-f66e-0ddaddfaf61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "list_res = []\n",
        "c1 = Classifier(0)\n",
        "res = c1.print_acc()\n",
        "list_res.append(res)\n",
        "\n",
        "c2 = Classifier(1)\n",
        "res = c2.print_acc()\n",
        "list_res.append(res)\n",
        "\n",
        "c3 = Classifier(2)\n",
        "res = c3.print_acc()\n",
        "list_res.append(res)\n",
        "\n",
        "!ls ./tmp/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.65833336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.85833335\n",
            "[1.0, 0.65833336, 0.85833335]\n",
            "checkpoint\t\t    model1.meta\n",
            "model\t\t\t    model2.data-00000-of-00001\n",
            "model0.data-00000-of-00001  model2.index\n",
            "model0.index\t\t    model2.meta\n",
            "model0.meta\t\t    model.data-00000-of-00001\n",
            "model1.data-00000-of-00001  model.index\n",
            "model1.index\t\t    model.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwLXKux5DnI9",
        "colab_type": "code",
        "outputId": "1559dae7-b5a3-4e9b-f1b7-63c5a413d69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "idx_max = np.argsort(list_res)[-1] #제일큰 acc index\n",
        "\n",
        "print('가장 높은확률로',ys_name[idx_max],\"입니다.\")\n",
        "\n",
        "# gra = tf.Graph()\n",
        "# with gra.as_default() :\n",
        "#     idx_max = np.argsort(list_res)[-1] #제일큰 acc index\n",
        "\n",
        "#     #label 만들기\n",
        "#     label = np.array(list(map(lambda ys : 1 if ys != one else 0, ys)))\n",
        "#     label = np.reshape(label, (-1,1))\n",
        "#     #print(label.shape)\n",
        "\n",
        "#     con_xs_ys = np.concatenate((xs,label), axis = 1)\n",
        "\n",
        "#     #train _ test split\n",
        "#     train_df, test_df = train_test_split(con_xs_ys,\n",
        "#                                         stratify=con_xs_ys[:,-1],\n",
        "#                                         train_size=0.8)\n",
        "#     xs_train = train_df[:,:-1]\n",
        "#     #print(xs_train.shape)\n",
        "#     label_train = train_df[:,-1]\n",
        "#     label_train = np.reshape(label_train, (-1,1))\n",
        "\n",
        "#     xs_test = test_df[:,:-1]\n",
        "#     label_test = test_df[:,-1]\n",
        "#     label_test = np.reshape(label_test, (-1,1))\n",
        "\n",
        "\n",
        "#     with tf.Session() as sess :\n",
        "#         new_saver = tf.train.import_meta_graph('./tmp/model{}.meta'.format(idx_max))\n",
        "#         new_saver.restore(sess,'/tmp')\n",
        "#         acc = graph.get_tensor_by_name('acc:0')\n",
        "#         acc_ = sess.run([acc],feed_dict = {xs_holder : xs_train,\n",
        "#                                            ys_holder : label_train})\n",
        "\n",
        "#         print(\"acc:\", acc_)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "가장 높은확률로 setosa 입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQZ5H703Acy3",
        "colab_type": "code",
        "outputId": "5576144d-7a83-4cd3-c1c6-a8d1eff09468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "저장된 변수의 이름을 불러옵니다\n",
            "저장된 변수의 이름 [('Variable', [4, 1]), ('Variable_1', [1])]\n",
            "w : [[-0.18142082]\n",
            " [ 0.01615225]\n",
            " [-0.20999752]\n",
            " [-0.3797823 ]] w1 : [0.0137773]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tIEMAwhDJSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8AeNTYRt8VXw"
      },
      "source": [
        "#  \n",
        "\n",
        "---\n",
        "\n",
        "    Copyright(c) 2019 by Public AI. All rights reserved.<br>\n",
        "    Writen by PAI, SangJae Kang ( rocketgrowthsj@publicai.co.kr )  last updated on 2019/03/22\n",
        "\n",
        "---"
      ]
    }
  ]
}