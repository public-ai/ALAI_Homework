{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"One_VS_ALL_IrisClassifier.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"je1nCDIAtS2e"},"source":[" ╔══<i><b>&nbsp;Alai-DeepLearning&nbsp;</b></i>══════════════════════════════════╗\n","###  &nbsp;&nbsp; **✎&nbsp;&nbsp;Week 5. machine learning basis**\n","# Homework 2. Multi classification\n","\n","### _Objective_\n","Tensorflow 을 이용해서 One Vs All 전략을 이용해 다중 classification 모델을 생성합니다.\n","\n","아래 순서에 맞게 프로그램을 작성해 주세요.\n","1. Setosa  Vs Versicolour, Virginica 모델 구현\n"," - 학습시 Tensorboard 을 이용해 loss 와 accuracy 을 추적해 주세요. \n"," - 학습 동안 acc 가 가장 높은 모델을 저장해 주세요.\n","2. Versicolour Vs Setosa, Virginica 모델 구현\n","  - 학습시 Tensorboard 을 이용해 loss 와 accuracy 을 추적해 주세요. \n"," - 학습 동안 acc 가 가장 높은 모델을 저장해 주세요.\n","3. Virginica Vs Setosa, Versicolour 모델 구현\n","  - 학습시 Tensorboard 을 이용해 loss 와 accuracy 을 추적해 주세요. \n"," - 학습 동안 acc 가 가장 높은 모델을 저장해 주세요.\n","4. 저장된 3개의 모델을 불러온 후 가장 높은 확률이 나오는 값을 선택합니다. <br>\n","가령 아래의 경우 **Versicolour** 을 선택합니다.\n","\n","| class        | probabilty |\n","|--------------|------------|\n","| Setosa       | 0.7        |\n","| Versicolour  | 0.9        |\n","| Virginica    | 0.3        |\n","\n","학습이 끝난후 모든 데이터를 평가한 후 accuracy 을 측정합니다.\n","\n","╚═══════════════════════════════════════════════╝"]},{"cell_type":"code","metadata":{"id":"9EjkThCn6qnZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uFcxTzkayJCS","colab":{}},"source":["%matplotlib inline\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CDRbefeWyJCR"},"source":["## Setosa  Vs Versicolour, Virginica 모델 구현 "]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"c16be0cd-2913-4d9a-c500-c846666b9ec8","id":"N8dq-IE-yJCK","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["import os\n","import numpy as np\n","from sklearn.datasets import load_iris\n","import tensorflow as tf\n","\n","\n","class IrisClassifier(object):\n","    def __init__(self, target_index, root_path):\n","        self.global_step = 0\n","        self.max_acc = 0\n","        self.graph = tf.Graph()\n","        self.root_path = root_path\n","\n","        self.target_index = target_index\n","        self._data_extractor()\n","        self._data_normalization()\n","        self._build()\n","\n","        with self.graph.as_default():\n","            self.sess = tf.Session()\n","            self.sess.run(tf.global_variables_initializer())\n","\n","    def _data_extractor(self):\n","        \"\"\"\n","        One Vs ALL 모델을 위해 Iris 데이터를 추출합니다.\n","        target 데이터의 라벨을 1로 하고 나머지 데이터의 라벨을 0으로 합니다.\n","        \"\"\"\n","        iris = load_iris()\n","        self.xs_data = iris['data']\n","        self.ys_data = iris['target']\n","        self.ys_data = np.where(self.ys_data == self.target_index, [1], [0])\n","\n","    def _data_normalization(self):\n","        self.xs_norm = (self.xs_data - self.xs_data.min(axis=0)) / \\\n","                  (self.xs_data.max(axis=0) - self.xs_data.min(axis=0))\n","\n","    def _build(self):\n","        with self.graph.as_default():\n","            self.xs = tf.placeholder(shape=[None, 4], dtype=tf.float32, name='xs')\n","            xs_concat = tf.concat([self.xs, tf.ones(dtype=tf.float32, shape=[tf.shape(self.xs)[0], 1])], axis=1)\n","            self.ys = tf.placeholder(shape=[None], dtype=tf.float32, name='ys')\n","            ys_res = tf.reshape(self.ys, shape=[-1, 1])\n","            self.lr = tf.placeholder(shape=[], dtype=tf.float32, name='lr')\n","\n","            # weights\n","            rand_ws = tf.random_normal(shape=[4 + 1, 1], dtype=tf.float32)\n","            ws = tf.Variable(rand_ws, name='ws')\n","            layer = tf.matmul(xs_concat, ws)\n","            pred = 1 / (1 + tf.exp(-layer))\n","\n","            # loss\n","            self.loss = -tf.reduce_mean(self.ys * tf.log(pred), name='loss')\n","            delta_ws = tf.matmul(tf.transpose(xs_concat), pred - ys_res)\n","\n","            # training step\n","            self.step = tf.assign_sub(ws, delta_ws * self.lr, name='step')\n","\n","            # Metric accruracy\n","            self.pred = tf.reshape(pred, shape=[-1], name='pred')\n","            pred_cls = tf.cast(self.pred >= 0.5, tf.float32)\n","            tf.where()\n","            self.acc = tf.reduce_mean(tf.cast(tf.equal(pred_cls, self.ys), tf.float32), name='acc')\n","\n","            # add Tensorboard\n","            self.train_writer = tf.summary.FileWriter(os.path.join(self.root_path, 'train'))\n","            self.eval_writer = tf.summary.FileWriter(os.path.join(self.root_path, 'eval'))\n","            tf.summary.scalar(name='loss', tensor=self.loss)\n","            tf.summary.scalar(name='accuracy', tensor=self.acc)\n","            self.merged = tf.summary.merge_all()\n","\n","            # Saver\n","            self.saver = tf.train.Saver()\n","            self.save_path = os.path.join(self.root_path, 'models/model')\n","            os.makedirs(self.save_path, exist_ok=True)\n","\n","    def training(self, max_iter):\n","        with self.graph.as_default():\n","            fetches = [self.step, self.acc, self.loss, self.merged]\n","            feed_dict = {self.xs: self.xs_norm, self.ys: self.ys_data, self.lr: 0.01}\n","            acc_list = []\n","            loss_list = []\n","            for i in range(max_iter):\n","                _, acc_, loss_, merged_ = self.sess.run(fetches, feed_dict)\n","                self.global_step += 1\n","                self.train_writer.add_summary(merged_, self.global_step)\n","                acc_list.append(acc_)\n","                loss_list.append(loss_)\n","            print('Train Accuracy : {}, Loss : {}'.format(np.mean(acc_list), np.mean(loss_list)))\n","\n","    def eval(self, save_flag=True):\n","        with self.graph.as_default():\n","            fetches = [self.acc, self.loss, self.merged]\n","            feed_dict = {self.xs: self.xs_norm, self.ys: self.ys_data}\n","            acc_, loss_, merged_ = self.sess.run(fetches, feed_dict)\n","            print('Eval Accuracy : {}, Loss : {}'.format(acc_, loss_))\n","\n","            if (acc_ > self.max_acc) and save_flag:\n","                print('Model Saved!')\n","                self.saver.save(self.sess, save_path=self.save_path)\n","\n","            self.eval_writer.add_summary(merged_, self.global_step)\n","\n","    def restore_model(self):\n","        with self.graph.as_default():\n","            saver = tf.train.Saver()\n","            saver.restore(self.sess, self.save_path)\n","\n","    def get_prediction(self):\n","        feed_dict = {self.xs: self.xs_norm}\n","        return self.sess.run(self.pred, feed_dict)\n","\n","\n","class OVA(object):\n","\n","    def __init__(self):\n","        self._data_extractor()\n","        self._data_normalization()\n","\n","        self.sento_classifier = IrisClassifier(0, 'sentosa')\n","        self.vesi_classifier = IrisClassifier(1, 'Versicolor')\n","        self.vigin_classifier = IrisClassifier(2, 'Virginica')\n","\n","    def _data_extractor(self):\n","        \"\"\"\n","        One Vs ALL 모델을 위해 Iris 데이터를 추출합니다.\n","        target 데이터의 라벨을 1로 하고 나머지 데이터의 라벨을 0으로 합니다.\n","        \"\"\"\n","        iris = load_iris()\n","        self.xs_data = iris['data']\n","        self.ys_data = iris['target']\n","\n","    def _data_normalization(self):\n","        self.xs_norm = (self.xs_data - self.xs_data.min(axis=0)) / \\\n","                  (self.xs_data.max(axis=0) - self.xs_data.min(axis=0))\n","\n","    def training(self):\n","        self.sento_classifier.training(max_iter=1000)\n","        self.sento_classifier.eval()\n","\n","        self.vesi_classifier.training(max_iter=1000)\n","        self.vesi_classifier.eval()\n","\n","        self.vigin_classifier.training(max_iter=1000)\n","        self.vigin_classifier.eval()\n","\n","    def restore_models(self):\n","        classifiers = [self.sento_classifier, self.vesi_classifier, self.vigin_classifier]\n","        for classifier in classifiers:\n","            with classifier.graph.as_default():\n","                saver = tf.train.Saver()\n","                saver.restore(classifier.sess, classifier.save_path)\n","\n","    def evaluation(self):\n","        predictions = [self.sento_classifier.get_prediction(), self.vesi_classifier.get_prediction(),\n","                       self.vigin_classifier.get_prediction()]\n","        pred_cls = np.argmax(np.stack(predictions, axis=-1), axis=1)\n","        acc = np.mean(self.ys_data == pred_cls)\n","        return acc\n","\n","if __name__ == '__main__':\n","\n","    ova = OVA()\n","    ova.training()\n","    ova.evaluation()\n","    ova.training()\n","    ova.evaluation()\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from sentosa/models/model\n","INFO:tensorflow:Restoring parameters from Versicolor/models/model\n","INFO:tensorflow:Restoring parameters from Virginica/models/model\n","0.9466666666666667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"1e7ad745-9fd5-496c-9088-9b9860ccf8f8","id":"Ex-yXOotyI6R","colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["# 다시 학습하지 않고 저장된 모델을 불러와 평가할때 사용됩니다. \n","# 저장된 모델 불러와서 평가.\n","ova = OVA()\n","ova.restore_models\n","ova.evaluation()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","Train Accuracy : 0.9995866417884827, Loss : 1.3736305236816406\n","Eval Accuracy : 1.0, Loss : 1.6921262741088867\n","Model Saved!\n","Train Accuracy : 0.7206200361251831, Loss : 0.4587215483188629\n","Eval Accuracy : 0.7266666889190674, Loss : 0.4884854257106781\n","Model Saved!\n","Train Accuracy : 0.9667065143585205, Loss : 1.2461198568344116\n","Eval Accuracy : 0.9733333587646484, Loss : 1.7310360670089722\n","Model Saved!\n"],"name":"stdout"}]}]}