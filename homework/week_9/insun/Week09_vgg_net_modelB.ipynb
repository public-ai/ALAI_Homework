{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week09_vgg_net_modelB.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Dm71BZOKS2dR","colab_type":"code","outputId":"9d2db005-bbbf-48a8-863d-8a7a7473b028","executionInfo":{"status":"ok","timestamp":1560823485427,"user_tz":-540,"elapsed":6562,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["%matplotlib inline\n","!pip install tensorboardcolab\n","\n","import numpy as np \n","import tensorflow as tf \n","import matplotlib.pyplot as plt\n","import os\n","from tqdm import tqdm\n","import tensorboardcolab"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"fMckkTBoTDxV","colab_type":"code","outputId":"4a972cb9-934c-4438-926d-4dc36ff90ce9","executionInfo":{"status":"ok","timestamp":1560823489626,"user_tz":-540,"elapsed":10707,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["# load cifar10 dataset \n","from keras.datasets import cifar10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-_00tFXVTIkn","colab_type":"code","outputId":"a39cdd8e-a829-4dc3-857d-d1abeaaae933","executionInfo":{"status":"ok","timestamp":1560823492018,"user_tz":-540,"elapsed":13012,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":92}},"source":["# reshape (None, 1) -> (None)\n","y_train, y_test = [np.reshape(y_train, [-1]), np.reshape(y_test, [-1])]\n","\n","# normalization \n","x_train, x_test = [(x_train - x_train.max()) / (x_train.max() - x_train.min()),\n","                   (x_test - x_test.max()) / (x_test.max() - x_test.min())]\n","\n","# N class\n","n_classes = 10\n","print('image shape : {}, label shape : {} '.format(x_train.shape, y_train.shape))\n","print('image shape : {}, label shape : {} '.format(x_test.shape, y_test.shape))\n","print('train minimun : {}, train_maximum : {} '.format(x_train.min(), x_train.max()))\n","print('tests minimun : {}, test_maximum : {} '.format(x_test.min(), x_test.max()))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["image shape : (50000, 32, 32, 3), label shape : (50000,) \n","image shape : (10000, 32, 32, 3), label shape : (10000,) \n","train minimun : 0.0, train_maximum : 1.0 \n","tests minimun : 0.0, test_maximum : 1.0 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fDdQkH56bJMO","colab_type":"code","outputId":"a8d8213c-823c-4f4e-d6d7-05b04b2a3d46","executionInfo":{"status":"ok","timestamp":1560823492023,"user_tz":-540,"elapsed":12958,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["temp = x_train\n","ratio = int(len(x_train) * 0.7)\n","ratio_end = int(len(x_train) * 1.0)  ### TODO\n","\n","x_train = temp[0:ratio, :, :, :]\n","x_validation = temp[ratio:ratio_end , :, :, :]\n","\n","y_train_label = y_train[0:ratio]\n","y_validation_label = y_train[ratio:ratio_end ]\n","\n","print(y_train_label[:10]) # label이 one_hot encoding상태가 아니다.\n","\n","print(x_train.shape, y_train_label.shape)\n","print(x_validation.shape, y_validation_label.shape)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[6 9 9 4 1 1 2 7 8 3]\n","(35000, 32, 32, 3) (35000,)\n","(15000, 32, 32, 3) (15000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mnZl2rmnLdKw","colab_type":"text"},"source":["## Data Provider"]},{"cell_type":"code","metadata":{"id":"Tpg4Xv_5Lckl","colab_type":"code","colab":{}},"source":["class DataProvider(object):\n","    def __init__(self, x, y):\n","        self.epoch_count = 0\n","        \n","        self.data = x\n","        self.label = y\n","        \n","        npr.seed(42)\n","        \n","        self.indices = self.generate_indices()\n","        \n","    def generate_indices(self):\n","        indices = list(range(len(self.data)))\n","        npr.shuffle(indices)\n","        \n","        return indices\n","    \n","    def next_batch(self, batch_size):\n","        idx = batch_size\n","        if len(self.indices) < batch_size:\n","            print(\"all data consumed, epoch + 1\")\n","            self.epoch_count += 1\n","            self.indices = self.generate_indices()\n","    \n","        target_indices = self.indices[:batch_size]\n","        del self.indices[:batch_size]\n","        \n","        return self.data[target_indices] , self.label[target_indices]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n2bPbJdyLlOS","colab_type":"code","colab":{}},"source":["def cifar_generator(data, labels, batch_size=32):\n","    start_idx = 0\n","    num_step = len(data) // batch_size\n","    indexes = np.arange(0, len(data))\n","    while True:\n","        if start_idx >= num_step-1:\n","            np.random.shuffle(indexes)\n","            start_idx = 0\n","        else:\n","            start_idx += 1            \n","        batch_index = indexes[start_idx*batch_size:\n","                              (start_idx+1)*batch_size]\n","\n","        batch_data = data[batch_index]\n","        batch_label = labels[batch_index]\n","\n","        yield batch_data, batch_label"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tppzG1VKq6kj","colab_type":"text"},"source":["## Model B : Build  --> Model A와 동일한 Structure이고, Optimizer만 Momentum으로 변경함"]},{"cell_type":"code","metadata":{"id":"SVMczcqNq6Np","colab_type":"code","outputId":"9a8af201-3082-4c0f-ac94-003c94f22420","executionInfo":{"status":"ok","timestamp":1560823493463,"user_tz":-540,"elapsed":14270,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":280}},"source":["graph = tf.Graph()\n","with graph.as_default() :\n","    xs = tf.placeholder(tf.float32, (None, 32, 32, 3), name='xs') # 32*32 = 1024\n","    ys = tf.placeholder(tf.int32, (None), name='ys')\n","    lr = tf.placeholder_with_default(0.001, (), name='lr')\n","    wd = tf.placeholder_with_default(0.9, (), name='wd')\n","    is_train = tf.placeholder_with_default(False, (), name='is_train')\n","    m = tf.placeholder_with_default(0.9, (), name='momentum')\n","    \n","    with tf.name_scope('conv1') :   ## filters is number of channels\n","        kernel_init   = tf.zeros([3, 3, 3, 32]) \n","        bias_init     = tf.zeros([32])\n","        conv1_kernel1 = tf.Variable(kernel_init, name='kernel1')               \n","        conv1_bias1   = tf.Variable(bias_init, name='bias1')\n","        \n","        layer         = tf.nn.conv2d(xs, conv1_kernel1, strides=[1,1,1,1], padding='SAME')\n","        layer         = layer + conv1_bias1\n","        layer         = tf.nn.relu(layer)\n","        \n","        kernel_init   = tf.zeros([3, 3, 32, 32]) \n","        bias_init     = tf.zeros([32])\n","        conv1_kernel2 = tf.Variable(kernel_init, name='kernel2')     \n","        conv1_bias2   = tf.Variable(bias_init, name='bias2')\n","        \n","        layer         = tf.nn.conv2d(layer, conv1_kernel2, strides=[1,1,1,1], padding='SAME') \n","        layer         = layer + conv1_bias2\n","        layer         = tf.nn.relu(layer)\n","          \n","            \n","    with tf.name_scope('conv2') :  \n","        kernel_init   = tf.zeros([3, 3, 32, 64]) \n","        bias_init     = tf.zeros([64])\n","        conv2_kernel1 = tf.Variable(kernel_init, name='kernel1')    \n","        conv2_bias1   = tf.Variable(bias_init, name='bias1')    \n","        \n","        layer         = tf.nn.conv2d(layer, conv2_kernel1, strides=[1,1,1,1], padding='SAME') \n","        layer         = layer + conv2_bias1\n","        layer         = tf.nn.relu(layer)\n","    \n","        kernel_init   = tf.zeros([3, 3, 64, 64]) \n","        bias_init     = tf.zeros([64])\n","        conv2_kernel2 = tf.Variable(kernel_init, name='kernel2')   \n","        conv2_bias2   = tf.Variable(bias_init, name='bias2')    \n","        \n","        layer         = tf.nn.conv2d(layer, conv2_kernel2, strides=[1,1,1,1], padding='SAME')    \n","        layer         = layer + conv2_bias2\n","        layer         = tf.nn.relu(layer)\n","    \n","        pool          = tf.layers.MaxPooling2D(pool_size=[2,2], strides=[2,2])(layer)        \n","\n","    with tf.name_scope('conv3') :       \n","        kernel_init   = tf.zeros([3, 3, 64, 128]) \n","        bias_init     = tf.zeros([128])\n","        conv3_kernel2 = tf.Variable(kernel_init, name='kernel2')           \n","        conv3_bias2   = tf.Variable(bias_init, name='bias2')    \n","        \n","        layer         = tf.nn.conv2d(pool, conv3_kernel2, strides=[1,3,3,1], padding='SAME') \n","        layer         = layer + conv3_bias2\n","        layer         = tf.nn.relu(layer)\n","    \n","        pool          = tf.layers.MaxPooling2D(pool_size=[2,2], strides=[2,2])(layer)      \n","\n","    with tf.name_scope('Reconstruct') : \n","        flatten       = tf.layers.flatten(pool)\n","        in_           = flatten.shape[1] \n","        \n","        fc1_weights1  = tf.Variable(tf.zeros(shape = [in_, 1024], dtype = tf.float32), name = \"fc1_weights1\")\n","        fc1_bias1     = tf.Variable(tf.zeros(shape = [1024], dtype = tf.float32), name = \"fc1_bias1\")\n","        fc1_logits    = tf.matmul(flatten, fc1_weights1) + fc1_bias1\n","        fc1_act       = tf.nn.relu(fc1_logits)\n","        fc1_dropout   = tf.layers.Dropout(0.5)(fc1_act, training = is_train)\n","        fc1_result    = tf.identity(fc1_dropout, \"fc1_result\")\n","        \n","        fc2_weights1  = tf.Variable(tf.zeros(shape = [1024, 1024], dtype = tf.float32), name = \"fc2_weights1\")\n","        fc2_bias1     = tf.Variable(tf.zeros(shape = [1024], dtype = tf.float32), name = \"fc2_bias1\")\n","        fc2_logits    = tf.matmul(fc1_result, fc2_weights1) + fc2_bias1\n","        fc2_act       = tf.nn.relu(fc2_logits)\n","        fc2_dropout   = tf.layers.Dropout(0.5)(fc2_act, training = is_train)\n","        fc2_result    = tf.identity(fc2_dropout, \"fc2_result\")\n","        \n","        y_pred        = tf.layers.Dense(10, activation=None, name='y_pred')(fc2_result) \n","    # Layer #\tKernel Stride\tDilation\tPadding\tInput Size\tOutput Size\tReceptive Field\n","    #    1\t      3\t       1\t   1\t       2\t      32    \t 32\t          3\n","    #    2\t      3\t       1\t   1\t       2\t      32    \t 32\t          5\n","    #    3\t      3\t       1\t   1\t       2\t      32    \t 32\t          7\n","    #    4\t      3\t       1\t   1\t       2\t      32    \t 32\t          9\n","    #    5\t      2\t       2\t   1\t       0\t      32    \t 16\t          10\n","    #    6\t      3\t       3\t   1\t       1\t      16    \t 6\t          14\n","    #    7\t      2\t       2\t   1\t       0\t      6\t         3 \t          20       \n","    \n","    with tf.name_scope('Loss') :\n","        sce_loss      = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=ys, logits=y_pred))\n","        l2_loss       = tf.add_n([tf.nn.l2_loss(var) for var in tf.global_variables()])\n","        loss          = sce_loss + wd * l2_loss\n","    loss = tf.identity(loss, name='loss')\n","        \n","    with tf.name_scope('metric') :\n","        rmse = tf.sqrt(loss)\n","    \n","    with tf.name_scope('accuracy') :\n","        pred        = tf.cast(tf.arg_max(y_pred, 1), tf.int32)\n","        correct     = tf.equal(pred, ys)\n","        accuracy    = tf.reduce_mean(tf.cast(correct, tf.float32))\n","        \n","        # add tensor to tensorboard\n","        acc_tb      = tf.summary.scalar(name='accuracy', tensor=accuracy)\n","\n","    with tf.name_scope('train') :\n","        global_step = tf.train.get_or_create_global_step()\n","        #train_op   = tf.train.AdamOptimizer(lr).minimize(loss, global_step = global_step)\n","        \n","        optimizer   = tf.train.MomentumOptimizer(lr, momentum = m, use_nesterov = False)\n","        train_op    = optimizer.minimize(loss, global_step = global_step)\n","        "],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0618 02:04:50.449737 140573816301440 deprecation.py:323] From <ipython-input-7-3e1aa8e8830e>:64: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","W0618 02:04:50.761130 140573816301440 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0618 02:04:51.226019 140573816301440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0618 02:04:51.254084 140573816301440 deprecation.py:323] From <ipython-input-7-3e1aa8e8830e>:101: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.math.argmax` instead\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Nyn0SDbfrGRV","colab_type":"text"},"source":["## Model B : Train"]},{"cell_type":"markdown","metadata":{"id":"G0hYYOQxyonM","colab_type":"text"},"source":["### Load trained weight and bias"]},{"cell_type":"code","metadata":{"id":"dIDOTTlnUBBu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":131},"outputId":"7a907284-7f70-41ce-bd62-46a17f7d1095","executionInfo":{"status":"ok","timestamp":1560823519668,"user_tz":-540,"elapsed":40438,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!mkdir ./model\n","!cp gdrive/My\\ Drive/vgg/* model/ # from, to 임"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0YTr5PuHZaK3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":56},"outputId":"995a4877-bde7-4452-a0e5-5fb99362cad4","executionInfo":{"status":"ok","timestamp":1560823519674,"user_tz":-540,"elapsed":40398,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}}},"source":["from tensorflow.python.training import checkpoint_utils as cp\n","\n","# 변수 불러오기\n","var_names = cp.list_variables('./model/vgg_net_model_a')   \n","print(var_names)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[('Reconstruct/fc1_bias1', [1024]), ('Reconstruct/fc1_bias1/Adam', [1024]), ('Reconstruct/fc1_bias1/Adam_1', [1024]), ('Reconstruct/fc1_weights1', [1152, 1024]), ('Reconstruct/fc1_weights1/Adam', [1152, 1024]), ('Reconstruct/fc1_weights1/Adam_1', [1152, 1024]), ('Reconstruct/fc2_bias1', [1024]), ('Reconstruct/fc2_bias1/Adam', [1024]), ('Reconstruct/fc2_bias1/Adam_1', [1024]), ('Reconstruct/fc2_weights1', [1024, 1024]), ('Reconstruct/fc2_weights1/Adam', [1024, 1024]), ('Reconstruct/fc2_weights1/Adam_1', [1024, 1024]), ('conv1/bias1', [32]), ('conv1/bias1/Adam', [32]), ('conv1/bias1/Adam_1', [32]), ('conv1/bias2', [32]), ('conv1/bias2/Adam', [32]), ('conv1/bias2/Adam_1', [32]), ('conv1/kernel1', [3, 3, 3, 32]), ('conv1/kernel1/Adam', [3, 3, 3, 32]), ('conv1/kernel1/Adam_1', [3, 3, 3, 32]), ('conv1/kernel2', [3, 3, 32, 32]), ('conv1/kernel2/Adam', [3, 3, 32, 32]), ('conv1/kernel2/Adam_1', [3, 3, 32, 32]), ('conv2/bias1', [64]), ('conv2/bias1/Adam', [64]), ('conv2/bias1/Adam_1', [64]), ('conv2/bias2', [64]), ('conv2/bias2/Adam', [64]), ('conv2/bias2/Adam_1', [64]), ('conv2/kernel1', [3, 3, 32, 64]), ('conv2/kernel1/Adam', [3, 3, 32, 64]), ('conv2/kernel1/Adam_1', [3, 3, 32, 64]), ('conv2/kernel2', [3, 3, 64, 64]), ('conv2/kernel2/Adam', [3, 3, 64, 64]), ('conv2/kernel2/Adam_1', [3, 3, 64, 64]), ('conv3/bias2', [128]), ('conv3/bias2/Adam', [128]), ('conv3/bias2/Adam_1', [128]), ('conv3/kernel2', [3, 3, 64, 128]), ('conv3/kernel2/Adam', [3, 3, 64, 128]), ('conv3/kernel2/Adam_1', [3, 3, 64, 128]), ('global_step', []), ('train/beta1_power', []), ('train/beta2_power', []), ('y_pred/bias', [10]), ('y_pred/bias/Adam', [10]), ('y_pred/bias/Adam_1', [10]), ('y_pred/kernel', [1024, 10]), ('y_pred/kernel/Adam', [1024, 10]), ('y_pred/kernel/Adam_1', [1024, 10])]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PtRu2MUdFODn","colab_type":"code","colab":{}},"source":["# 값 불러오기\n","conv1_w1  = cp.load_variable('./model/vgg_net_model_a', 'conv1/kernel1')   \n","conv1_b1  = cp.load_variable('./model/vgg_net_model_a', 'conv1/bias1')\n","conv1_w2  = cp.load_variable('./model/vgg_net_model_a', 'conv1/kernel2')   \n","conv1_b2  = cp.load_variable('./model/vgg_net_model_a', 'conv1/bias2')\n","\n","conv2_w1  = cp.load_variable('./model/vgg_net_model_a', 'conv2/kernel1')   \n","conv2_b1  = cp.load_variable('./model/vgg_net_model_a', 'conv2/bias1')\n","conv2_w2  = cp.load_variable('./model/vgg_net_model_a', 'conv2/kernel2')   \n","conv2_b2  = cp.load_variable('./model/vgg_net_model_a', 'conv2/bias2')\n","\n","conv3_w2  = cp.load_variable('./model/vgg_net_model_a', 'conv3/kernel2')    # 오타.. TODO\n","conv3_b2  = cp.load_variable('./model/vgg_net_model_a', 'conv3/bias2')\n","\n","f1_w1    = cp.load_variable('./model/vgg_net_model_a', 'Reconstruct/fc1_weights1')   \n","f1_b1    = cp.load_variable('./model/vgg_net_model_a', 'Reconstruct/fc1_bias1')\n","f2_w1    = cp.load_variable('./model/vgg_net_model_a', 'Reconstruct/fc2_weights1')   \n","f2_b1    = cp.load_variable('./model/vgg_net_model_a', 'Reconstruct/fc2_bias1')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzLokE3qJ-iF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":56},"outputId":"91bae537-7d5d-4493-caaa-d8f64aa3ce84","executionInfo":{"status":"ok","timestamp":1560823519704,"user_tz":-540,"elapsed":40295,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}}},"source":["print(graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[<tf.Variable 'conv1/kernel1:0' shape=(3, 3, 3, 32) dtype=float32_ref>, <tf.Variable 'conv1/bias1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv1/kernel2:0' shape=(3, 3, 32, 32) dtype=float32_ref>, <tf.Variable 'conv1/bias2:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'conv2/kernel1:0' shape=(3, 3, 32, 64) dtype=float32_ref>, <tf.Variable 'conv2/bias1:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv2/kernel2:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'conv2/bias2:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv3/kernel2:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'conv3/bias2:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'Reconstruct/fc1_weights1:0' shape=(1152, 1024) dtype=float32_ref>, <tf.Variable 'Reconstruct/fc1_bias1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'Reconstruct/fc2_weights1:0' shape=(1024, 1024) dtype=float32_ref>, <tf.Variable 'Reconstruct/fc2_bias1:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'y_pred/kernel:0' shape=(1024, 10) dtype=float32_ref>, <tf.Variable 'y_pred/bias:0' shape=(10,) dtype=float32_ref>]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jTazVoc9zcd3","colab_type":"text"},"source":["## Model B : Train"]},{"cell_type":"code","metadata":{"id":"ZEShi1e3zefJ","colab_type":"code","outputId":"f58a79ea-3e90-4702-fc7e-7dd16be7f5a6","executionInfo":{"status":"ok","timestamp":1560823531755,"user_tz":-540,"elapsed":52302,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":279}},"source":["with graph.as_default() :\n","    \n","    log_dir = \"./log/vgg_net_model_b\"   \n","    lode_dir = \"./model/vgg_net_model_a\"\n","    save_dir = \"./model/vgg_net_model_b\"    # dir + file name.\n","    \n","    # 텐서보드에 연결합니다.\n","    # tbc = tensorboardcolab.TensorBoardColab(graph_path = log_dir)\n","    train_writer = tf.summary.FileWriter(logdir = log_dir)\n","    train_writer.add_graph(tf.get_default_graph())\n","    merged_all = tf.summary.merge_all()    \n","    \n","    sess = tf.Session()\n","    sess.run(tf.global_variables_initializer()) \n","    \n","    # Saver를 이용하지 않고 pretrain된 data를 불러와서 사용해보자.\n","    # Step2 : 기록\n","    # saver = tf.train.Saver(var_list = transfer_weights)\n","\n","    # loading parameters\n","    # saver.restore(sess, save_path = lode_dir)\n","\n","\n","    # Training\n","    batch_size = 1000\n","    n_epoch = 0 # 30\n","    n_step = int(len(x_train) // batch_size)  # //은 몫이다.\n","    learing_rate = 0.001\n","    weight_decay = 0.0005\n","    \n","    # instance 생성\n","    train_generator = cifar_generator(x_train, y_train_label, batch_size)\n","    \n","    train_loss = []\n","    valid_loss = []\n","    valid_acc = []\n","    cnt = 0\n","    minimum_loss = 1.1\n","    momentum = 0.9\n","\n","    \n","    # pre training된 weight, bais 넣기 ## Numpy array로 직접 넣기\n","    feed_dict = { xs : x_validation, ys : y_validation_label, \n","                 wd : 0, m : 0, is_train : False, \n","                 conv1_kernel1 : conv1_w1, conv1_bias1 : conv1_b1, \n","                 conv1_kernel2 : conv1_w2, conv1_bias2 : conv1_b2, \n","                 conv2_kernel1 : conv2_w1, conv2_bias1 : conv2_b1, \n","                 conv2_kernel2 : conv2_w2, conv2_bias2 : conv2_b2, \n","                 conv3_kernel2 : conv3_w2, conv3_bias2 : conv3_b2,\n","                 fc1_weights1  : f1_w1,    fc1_bias1 : f1_b1,\n","                 fc2_weights1  : f2_w1,    fc2_bias1 : f2_b1}\n","    loss_, acc_, fc2_weights1_= sess.run([rmse, accuracy, fc2_weights1], feed_dict = feed_dict)\n","    print(\"Loading결과 확인 -> loss = {:.4f}, acc = {:.2f}%\".format(loss_, acc_*100))\n","    print(\"weight를 제대로 가져오는지 확인 -> \", fc2_weights1_)\n","\n","\n","        \n","    # for i in tqdm(range(n_epoch)) :\n","    #     for step in range(n_step) :\n","    #         batch_xs, batch_ys = next(train_generator)\n","    #         _, train_loss_, tbs_train_ = sess.run([train_op, rmse, merged_all], feed_dict = { xs: batch_xs, \n","    #                                                                                           ys: batch_ys, \n","    #                                                                                           lr: learing_rate,\n","    #                                                                                           wd : weight_decay,\n","    #                                                                                           m : momentum,\n","    #                                                                                           is_train : True})\n","    #         train_writer.add_summary(tbs_train_, global_step=cnt) # 흠 되야 하는데 안된다.\n","    #         cnt += 1\n","    #         train_loss.append(train_loss_)\n","    #         \n","    #         # check validation set\n","    #         if step % 100 == 0 :\n","    #             loss_, acc_ = sess.run([rmse, accuracy], feed_dict = { xs: x_validation, \n","    #                                                                    ys: y_validation_label,\n","    #                                                                    wd : weight_decay,\n","    #                                                                    m : momentum,\n","    #                                                                    is_train : False})\n","    #             valid_loss.append(loss_)\n","    #             valid_acc.append(acc_)\n","    #             \n","    #             # Save the model\n","    #             if loss_ < minimum_loss :\n","    #                 print(\"log current model!\")\n","    #                 minimum_loss = loss_\n","    #                 saver.save(sess, save_path = save_dir)\n","    #     print(\"loss = {:.4f}, acc = {:.2f}%\".format(loss_, acc_*100))\n","    # print(\"loss = {:.4f}, acc = {:.2f}%\".format(loss_, acc_*100))\n","    \n","    train_writer.flush() # file을 disk에 쓴다"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Loading결과 확인 -> loss = 1.5269, acc = 16.36%\n","weight를 제대로 가져오는지 확인 ->  [[ 2.71307137e-02 -1.25479437e-02  2.35868134e-02 ...  3.18341865e-03\n","  -1.23903230e-02 -3.40513252e-02]\n"," [ 1.76205412e-02  8.06861464e-03 -1.41466055e-02 ...  2.62078624e-02\n","  -1.16349792e-03 -1.31203244e-02]\n"," [ 1.31812096e-02  1.92907900e-02 -8.44401121e-03 ... -4.72040083e-05\n","   3.89633328e-02  4.45121853e-03]\n"," ...\n"," [ 1.60037894e-02 -1.04974322e-02  1.55837657e-02 ...  2.07463447e-02\n","   2.84298230e-03  2.46870182e-02]\n"," [ 9.52524599e-04 -3.47122294e-03  3.87140177e-02 ...  1.65685099e-02\n","  -2.02795472e-02 -1.26976082e-02]\n"," [ 3.02585840e-06  1.30706057e-05  7.41337362e-06 ... -5.87957256e-05\n","   1.98324210e-06  5.80111646e-06]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"orlNn-vYc6-Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":521},"outputId":"b24a2069-dbb6-4ab9-ee46-b91d6349b9d8","executionInfo":{"status":"ok","timestamp":1560823531975,"user_tz":-540,"elapsed":52465,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}}},"source":["plt.plot(np.arange(0, len(train_loss), 1), train_loss)\n","plt.show()\n","plt.plot(np.arange(0, len(valid_loss), 1), valid_loss)\n","plt.show() # train과 validation 모두 봐야 한다."],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNQyDJKlhGCRJjf8FFDYZsBaypoYAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNQyDJKlhGCRJjf8FFDYZsBaypoYAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"9y81GK9E5vo_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"9c33300c-db74-4304-ed20-20f1f4284bfa","executionInfo":{"status":"ok","timestamp":1560823535983,"user_tz":-540,"elapsed":56430,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!mkdir gdrive/My\\ Drive/vgg\n","!mv ./model/vgg* gdrive/My\\ Drive/vgg\n","!mv ./model/checkpoint gdrive/My\\ Drive/vgg"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","mkdir: cannot create directory ‘gdrive/My Drive/vgg’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"awRbkN9ML7Fv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dAIoXmvpC9rd","colab_type":"code","colab":{}},"source":["# with graph.as_default() :\n","#     \n","#     sess = tf.Session()\n","#     sess.run([tf.global_variables_initializer(),\n","#               tf.local_variables_initializer()])    \n","#     print(graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n","#     \n","#     lode_dir = \"./model/vgg_net_model_a\"\n","#     \n","#     # meta graph  eval\n","#     saver = tf.train.import_meta_graph('./model/vgg_net_model_a.meta')\n","#     #saver.restore(sess, tf.train.latest_checkpoint('./'))\n","#     saver.restore(sess, save_path = lode_dir)\n","#         \n","#     layer1_w = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"convolution_layer_1/kernel:0\")\n","#     layer1_b = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"convolution_layer_1/bias:0\")\n","#     \n","#     layer2_w = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"convolution_layer_2/kernel:0\")\n","#     layer2_b = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"convolution_layer_2/bias:0\")\n","#     \n","#     layer3_w = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"convolution_layer_3/kernel:0\")\n","#     layer3_b = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"convolution_layer_3/bias:0\")\n","#     \n","#     layer3_w2 = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"convolution_layer_3/kernel_1:0\")\n","#     layer3_b2 = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"convolution_layer_3/bias_1:0\")\n","#     \n","#     fc1_w = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"FC1/kernel:0\")\n","#     fc1_b = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"FC1/bias:0\")\n","#     \n","#     fc2_w = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"FC2/kernel:0\")\n","#     fc2_b = graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"FC2/bias:0\")\n","#     \n","#     transfer_weights = layer1_w + layer1_b + \\\n","#                        layer2_w + layer2_b + \\\n","#                        layer3_w + layer3_b + layer3_w2 + layer3_b2 + \\\n","#                        fc1_w + fc1_b + fc2_w + fc2_b\n","#     \n","#     # transfer_weights = layer1_w\n","#     print(transfer_weights)"],"execution_count":0,"outputs":[]}]}