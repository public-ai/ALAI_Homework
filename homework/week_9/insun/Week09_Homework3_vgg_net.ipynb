{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week10_VGG Net.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Dm71BZOKS2dR","colab_type":"code","outputId":"e0930f40-c9a4-4053-f714-1e879312992d","executionInfo":{"status":"ok","timestamp":1560684830570,"user_tz":-540,"elapsed":6929,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["%matplotlib inline\n","!pip install tensorboardcolab\n","\n","import numpy as np \n","import tensorflow as tf \n","import matplotlib.pyplot as plt\n","import os\n","from tqdm import tqdm\n","import tensorboardcolab"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"fMckkTBoTDxV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"f1cd839d-4469-4d94-f497-53b1a75f1b02","executionInfo":{"status":"ok","timestamp":1560684843198,"user_tz":-540,"elapsed":19344,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}}},"source":["# load cifar10 dataset \n","from keras.datasets import cifar10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 10s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-_00tFXVTIkn","colab_type":"code","outputId":"f8636e0a-8d00-4156-decd-317923e13c10","executionInfo":{"status":"ok","timestamp":1560684845048,"user_tz":-540,"elapsed":21015,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["# reshape (None, 1) -> (None)\n","y_train, y_test = [np.reshape(y_train, [-1]), np.reshape(y_test, [-1])]\n","\n","# normalization \n","x_train, x_test = [(x_train - x_train.max()) / (x_train.max() - x_train.min()),\n","                   (x_test - x_test.max()) / (x_test.max() - x_test.min())]\n","\n","# N class\n","n_classes = 10\n","print('image shape : {}, label shape : {} '.format(x_train.shape, y_train.shape))\n","print('image shape : {}, label shape : {} '.format(x_test.shape, y_test.shape))\n","print('train minimun : {}, train_maximum : {} '.format(x_train.min(), x_train.max()))\n","print('tests minimun : {}, test_maximum : {} '.format(x_test.min(), x_test.max()))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["image shape : (50000, 32, 32, 3), label shape : (50000,) \n","image shape : (10000, 32, 32, 3), label shape : (10000,) \n","train minimun : 0.0, train_maximum : 1.0 \n","tests minimun : 0.0, test_maximum : 1.0 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fDdQkH56bJMO","colab_type":"code","outputId":"7c6e737a-4b2f-4497-b1f8-eb5f3da28172","executionInfo":{"status":"ok","timestamp":1560684845050,"user_tz":-540,"elapsed":20799,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["temp = x_train\n","ratio = int(len(x_train) * 0.7)\n","ratio_end = int(len(x_train) * 1.0)\n","\n","x_train = temp[0:ratio, :, :, :]\n","x_validation = temp[ratio:ratio_end , :, :, :]\n","\n","y_train_label = y_train[0:ratio]\n","y_validation_label = y_train[ratio:ratio_end ]\n","\n","print(y_train_label[:10]) # label이 one_hot encoding상태가 아니다.\n","\n","print(x_train.shape, y_train_label.shape)\n","print(x_validation.shape, y_validation_label.shape)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[6 9 9 4 1 1 2 7 8 3]\n","(35000, 32, 32, 3) (35000,)\n","(15000, 32, 32, 3) (15000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mnZl2rmnLdKw","colab_type":"text"},"source":["## Data Provider"]},{"cell_type":"code","metadata":{"id":"Tpg4Xv_5Lckl","colab_type":"code","colab":{}},"source":["class DataProvider(object):\n","    def __init__(self, x, y):\n","        self.epoch_count = 0\n","        \n","        self.data = x\n","        self.label = y\n","        \n","        npr.seed(42)\n","        \n","        self.indices = self.generate_indices()\n","        \n","    def generate_indices(self):\n","        indices = list(range(len(self.data)))\n","        npr.shuffle(indices)\n","        \n","        return indices\n","    \n","    def next_batch(self, batch_size):\n","        idx = batch_size\n","        if len(self.indices) < batch_size:\n","            print(\"all data consumed, epoch + 1\")\n","            self.epoch_count += 1\n","            self.indices = self.generate_indices()\n","    \n","        target_indices = self.indices[:batch_size]\n","        del self.indices[:batch_size]\n","        \n","        return self.data[target_indices] , self.label[target_indices]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n2bPbJdyLlOS","colab_type":"code","colab":{}},"source":["def cifar_generator(data, labels, batch_size=32):\n","    start_idx = 0\n","    num_step = len(data) // batch_size\n","    indexes = np.arange(0, len(data))\n","    while True:\n","        if start_idx >= num_step-1:\n","            np.random.shuffle(indexes)\n","            start_idx = 0\n","        else:\n","            start_idx += 1            \n","        batch_index = indexes[start_idx*batch_size:\n","                              (start_idx+1)*batch_size]\n","\n","        batch_data = data[batch_index]\n","        batch_label = labels[batch_index]\n","\n","        yield batch_data, batch_label"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Tsw-Lscq9yL","colab_type":"text"},"source":["## Model A : Build"]},{"cell_type":"code","metadata":{"id":"GfEHHa1ZT3id","colab_type":"code","outputId":"e504f665-d241-42fe-d94f-60e27d4a0a5a","executionInfo":{"status":"ok","timestamp":1560684846373,"user_tz":-540,"elapsed":17381,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":285}},"source":["graph = tf.Graph()\n","with graph.as_default() :\n","    xs = tf.placeholder(tf.float32, (None, 32, 32, 3), name='xs') # 32*32 = 1024\n","    ys = tf.placeholder(tf.int32, (None), name='ys')\n","    lr = tf.placeholder_with_default(0.001, (), name='lr')\n","    \n","    #with tf.name_scope('preprocessing') :\n","    #    a = tf.reduce_mean(tf.reduce_mean(xs[:,:,:,0], axis=0))\n","    #    b = tf.reduce_mean(tf.reduce_mean(xs[:,:,:,1], axis=0))\n","    #    c = tf.reduce_mean(tf.reduce_mean(xs[:,:,:,2], axis=0))\n","    #    print(a, b, c.dtype)\n","    #    combine = tf.stack([a, b, c], axis=0)\n","    #    print(combine)\n","    #    vgg_mean = tf.constant(combine, tf.float32)\n","    #    xs = xs - vgg_mean\n","    \n","    # with tf.name_scope('convolution_layer') :   ## filters is number of channels\n","    #     layer1 = tf.layers.Conv2D(filters=16, kernel_size=[2,2], strides=[1,1], padding='SAME', activation=tf.nn.relu)(xs)\n","    #     pool = tf.layers.MaxPooling2D(pool_size=[2,2], strides=[2,2])(layer1)\n","    #     \n","    #     layer2 = tf.layers.Conv2D(filters=32, kernel_size=[2,2], strides=[1,1], padding='SAME', activation=tf.nn.relu)(pool)\n","    #     pool = tf.layers.MaxPooling2D(pool_size=[2,2], strides=[2,2])(layer2)\n","    #     \n","    #     layer3 = tf.layers.Conv2D(filters=64, kernel_size=[3,3], strides=[1,1], padding='SAME', activation=tf.nn.relu)(pool)\n","    #     layer4 = tf.layers.Conv2D(filters=64, kernel_size=[3,3], strides=[1,1], padding='SAME', activation=tf.nn.relu)(layer3)\n","    #     pool = tf.layers.MaxPooling2D(pool_size=[2,2], strides=[2,2])(layer4)\n","    #     # receptive filed = 27, images size = 32, output imagesize = (4, 4)\n","    \n","    with tf.name_scope('convolution_layer_1') :   ## filters is number of channels\n","        kernel_init = tf.random.normal(shape=[2, 2, 3, 16], mean=0.0, stddev=0.1, dtype=tf.float32, name='kernel_init') # random normal \n","        kernel= tf.Variable(kernel_init, name='kernel')               \n","        bias_init = tf.zeros([16])\n","        bias = tf.Variable(bias_init, name='bias')\n","    \n","        layer = tf.nn.conv2d(xs, kernel, strides=[1,1,1,1], padding='SAME') # convolution and add bias   \n","        layer = layer + bias\n","        layer = tf.nn.relu(layer)\n","        \n","        pool = tf.layers.MaxPooling2D(pool_size=[2,2], strides=[2,2])(layer)\n","\n","    with tf.name_scope('convolution_layer_2') :   ## filters is number of channels\n","        kernel_init = tf.random.normal(shape=[2, 2, 16, 32], mean=0.0, stddev=0.1, dtype=tf.float32, name='kernel_init') # random normal \n","        kernel= tf.Variable(kernel_init, name='kernel')               \n","        bias_init = tf.zeros([32])\n","        bias = tf.Variable(bias_init, name='bias')\n","    \n","        layer = tf.nn.conv2d(pool, kernel, strides=[1,1,1,1], padding='SAME') # convolution and add bias    \n","        layer = layer + bias\n","        layer = tf.nn.relu(layer)\n","          \n","        pool = tf.layers.MaxPooling2D(pool_size=[2,2], strides=[2,2])(layer)\n","        \n","            \n","    with tf.name_scope('convolution_layer_3') :   ## filters is number of channels\n","        kernel_init = tf.random.normal(shape=[3, 3, 32, 64], mean=0.0, stddev=0.1, dtype=tf.float32, name='kernel_init') # random normal \n","        kernel= tf.Variable(kernel_init, name='kernel')               \n","        bias_init = tf.zeros([64])\n","        bias = tf.Variable(bias_init, name='bias')    \n","        layer = tf.nn.conv2d(pool, kernel, strides=[1,1,1,1], padding='SAME') # convolution and add bias   \n","        layer = layer + bias\n","        layer = tf.nn.relu(layer)\n","\n","        kernel_init2 = tf.random.normal(shape=[3, 3, 64, 64], mean=0.0, stddev=0.1, dtype=tf.float32, name='kernel_init') # random normal \n","        kernel2= tf.Variable(kernel_init2, name='kernel')               \n","        bias_init2 = tf.zeros([64])\n","        bias2 = tf.Variable(bias_init2, name='bias')    \n","        layer = tf.nn.conv2d(layer, kernel2, strides=[1,1,1,1], padding='SAME') # convolution and add bias      \n","        layer = layer + bias2\n","        layer = tf.nn.relu(layer)\n","    \n","        pool = tf.layers.MaxPooling2D(pool_size=[2,2], strides=[2,2])(layer)        \n","        \n","    # receptive filed = 27, images size = 32, output imagesize = (4, 4)\n","\n","    with tf.name_scope('Reconstruct') : \n","        flatten = tf.layers.flatten(pool)\n","        layer = tf.layers.Dense(1024, activation=tf.nn.relu)(flatten) # 32*32\n","        layer = tf.layers.Dense(1024, activation=tf.nn.relu)(layer)\n","        y_pred = tf.layers.Dense(10, activation=None, name='y_pred')(layer)\n","        \n","    with tf.name_scope('Loss') :\n","        loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=ys, logits=y_pred))\n","        print(loss.shape)\n","        \n","    with tf.name_scope('metric') :\n","        rmse = tf.sqrt(loss)\n","    \n","    with tf.name_scope('accuracy') :\n","        pred = tf.cast(tf.arg_max(y_pred, 1), tf.int32)\n","        correct = tf.equal(pred, ys)\n","        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n","        \n","        # add tensor to tensorboard\n","        acc_tb = tf.summary.scalar(name='accuracy', tensor=accuracy)\n","\n","    with tf.name_scope('train') :\n","        train_op = tf.train.AdamOptimizer(lr).minimize(loss)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0616 11:34:04.183500 140213799266176 deprecation.py:323] From <ipython-input-7-b22dbe9b31a9>:76: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","W0616 11:34:04.393238 140213799266176 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0616 11:34:04.714800 140213799266176 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0616 11:34:04.728788 140213799266176 deprecation.py:323] From <ipython-input-7-b22dbe9b31a9>:89: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.math.argmax` instead\n"],"name":"stderr"},{"output_type":"stream","text":["()\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j7mtgxmtrAg1","colab_type":"text"},"source":["## Model A : Train"]},{"cell_type":"code","metadata":{"id":"jAdWcs-2TJ4N","colab_type":"code","outputId":"a9bf94c0-02f3-41a1-b339-870c430b8984","executionInfo":{"status":"ok","timestamp":1560685718819,"user_tz":-540,"elapsed":881823,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":1877}},"source":["with graph.as_default() :\n","    \n","    # 텐서보드에 연결합니다. # sess.run보다 먼저 선언해야함. \n","    log_dir = \"./log/vgg_net\"    \n","    tbc = tensorboardcolab.TensorBoardColab(graph_path = log_dir)\n","    \n","    train_writer = tf.summary.FileWriter(logdir = log_dir)\n","    train_writer.add_graph(tf.get_default_graph())\n","    merged_all = tf.summary.merge_all()    \n","    \n","    sess = tf.Session()\n","    sess.run(tf.global_variables_initializer())\n","    \n","    # Step2 : 기록\n","    saver = tf.train.Saver()\n","    \n","    # Training\n","    batch_size = 30\n","    n_epoch = 100\n","    n_step = int(len(x_train) // batch_size)  # //은 몫이다.\n","    learing_rate = 0.0001\n","    \n","    # instance 생성\n","    train_generator = cifar_generator(x_train, y_train_label, batch_size)\n","    \n","\n","    # dropout 추가, training+validation accuray는 항상 같이 뽑아야 한다. \n","    # overfitting되는 곳을 알 수 있따! momentum으로 여기서 다시 학습하면 loss가 내려간다\n","    # Adam이 최소점까지 빨리 가는데,중간에 momentum으로 바꾸면 잘 내려가더라\n","    # reconstruct할때, 하나 만들고 다른 layer의 weights로 가는지 확인해보자. 이후에 두개로 \n","    # 이미지사이즈 224->32로 많이 줄엇다. filter개수나 4096개 같은것도 1/4로 줄이자\n","    \n","    train_loss = []\n","    valid_loss = []\n","    valid_acc = []\n","    cnt = 0\n","    for i in tqdm(range(n_epoch)) :\n","        for step in range(n_step) :\n","            batch_xs, batch_ys = next(train_generator)\n","            _, train_loss_, tbs_train_ = sess.run([train_op, rmse, merged_all], feed_dict = { xs: batch_xs, \n","                                                                                              ys: batch_ys, \n","                                                                                              lr: learing_rate})\n","            train_writer.add_summary(tbs_train_, global_step=cnt) # 흠 되야 하는데 안된다.\n","            cnt += 1\n","            train_loss.append(train_loss_)\n","            if step % 100 == 0 :\n","                loss_, acc_ = sess.run([rmse, accuracy], feed_dict = { xs: x_validation, \n","                                                                       ys: y_validation_label})\n","                valid_loss.append(loss_)\n","                valid_acc.append(acc_)\n","        print(\"loss = {:.4f}, acc = {:.2f}%\".format(loss_, acc_*100))\n","    print(\"loss = {:.4f}, acc = {:.2f}%\".format(loss_, acc_*100))\n","    \n","    # Save the model\n","    saver.save(sess, save_path='./model/vgg_net')\n","    \n","    train_writer.flush() # file을 disk에 쓴다"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","https://4ad59aab.ngrok.io\n"],"name":"stdout"},{"output_type":"stream","text":["  1%|          | 1/100 [00:13<22:28, 13.62s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.2451, acc = 43.65%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  2%|▏         | 2/100 [00:22<19:43, 12.08s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.1714, acc = 50.98%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  3%|▎         | 3/100 [00:30<17:46, 10.99s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.1193, acc = 55.66%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  4%|▍         | 4/100 [00:39<16:22, 10.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.1163, acc = 55.57%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  5%|▌         | 5/100 [00:47<15:21,  9.70s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.0829, acc = 58.82%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  6%|▌         | 6/100 [00:56<14:39,  9.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.0682, acc = 59.75%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  7%|▋         | 7/100 [01:04<14:06,  9.10s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.0497, acc = 61.21%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  8%|▊         | 8/100 [01:13<13:40,  8.91s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.0417, acc = 61.93%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  9%|▉         | 9/100 [01:21<13:19,  8.78s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.0364, acc = 62.97%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 10%|█         | 10/100 [01:30<13:03,  8.70s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.0281, acc = 63.65%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 11%|█         | 11/100 [01:38<12:49,  8.64s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.0124, acc = 65.08%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 12%|█▏        | 12/100 [01:47<12:37,  8.60s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.0437, acc = 63.44%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 13%|█▎        | 13/100 [01:55<12:25,  8.57s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.0348, acc = 65.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 14%|█▍        | 14/100 [02:03<12:14,  8.54s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.0585, acc = 65.04%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 15%|█▌        | 15/100 [02:12<12:03,  8.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.0608, acc = 65.16%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 16%|█▌        | 16/100 [02:20<11:54,  8.50s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.1202, acc = 63.50%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 17%|█▋        | 17/100 [02:29<11:44,  8.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.1044, acc = 65.20%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 18%|█▊        | 18/100 [02:37<11:35,  8.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.1313, acc = 65.39%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 19%|█▉        | 19/100 [02:46<11:26,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.1455, acc = 65.81%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 20%|██        | 20/100 [02:54<11:18,  8.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.2234, acc = 64.50%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 21%|██        | 21/100 [03:03<11:08,  8.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.2821, acc = 64.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 22%|██▏       | 22/100 [03:11<10:59,  8.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.2909, acc = 64.43%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 23%|██▎       | 23/100 [03:20<10:53,  8.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.2998, acc = 65.27%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 24%|██▍       | 24/100 [03:28<10:44,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.3612, acc = 64.17%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 25%|██▌       | 25/100 [03:37<10:39,  8.52s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.3464, acc = 64.45%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 26%|██▌       | 26/100 [03:45<10:32,  8.55s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.3968, acc = 64.94%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 27%|██▋       | 27/100 [03:54<10:21,  8.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.4035, acc = 64.95%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 28%|██▊       | 28/100 [04:02<10:11,  8.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.4204, acc = 65.09%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 29%|██▉       | 29/100 [04:11<10:02,  8.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.4562, acc = 64.69%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 30%|███       | 30/100 [04:19<09:54,  8.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.4823, acc = 63.65%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 31%|███       | 31/100 [04:28<09:44,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5185, acc = 63.07%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 32%|███▏      | 32/100 [04:36<09:35,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.4917, acc = 64.23%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 33%|███▎      | 33/100 [04:45<09:26,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.4651, acc = 64.37%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 34%|███▍      | 34/100 [04:53<09:18,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.4913, acc = 65.65%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 35%|███▌      | 35/100 [05:01<09:09,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.4912, acc = 65.21%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 36%|███▌      | 36/100 [05:10<09:00,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5269, acc = 64.61%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 37%|███▋      | 37/100 [05:18<08:51,  8.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5471, acc = 65.08%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 38%|███▊      | 38/100 [05:27<08:43,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5309, acc = 65.45%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 39%|███▉      | 39/100 [05:35<08:35,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5343, acc = 64.09%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 40%|████      | 40/100 [05:44<08:26,  8.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5608, acc = 65.35%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 41%|████      | 41/100 [05:52<08:18,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5746, acc = 64.60%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 42%|████▏     | 42/100 [06:01<08:09,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6080, acc = 65.14%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 43%|████▎     | 43/100 [06:09<08:01,  8.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5875, acc = 64.89%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 44%|████▍     | 44/100 [06:17<07:52,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6293, acc = 64.14%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 45%|████▌     | 45/100 [06:26<07:44,  8.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6227, acc = 63.87%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 46%|████▌     | 46/100 [06:34<07:36,  8.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6350, acc = 64.33%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 47%|████▋     | 47/100 [06:43<07:28,  8.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5743, acc = 65.03%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 48%|████▊     | 48/100 [06:51<07:20,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5620, acc = 65.80%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 49%|████▉     | 49/100 [07:00<07:12,  8.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5906, acc = 65.79%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|█████     | 50/100 [07:08<07:04,  8.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.5984, acc = 65.28%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 51%|█████     | 51/100 [07:17<06:55,  8.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6104, acc = 64.48%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 52%|█████▏    | 52/100 [07:25<06:46,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6201, acc = 64.74%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 53%|█████▎    | 53/100 [07:34<06:38,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6286, acc = 65.15%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 54%|█████▍    | 54/100 [07:42<06:28,  8.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6237, acc = 65.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 55%|█████▌    | 55/100 [07:51<06:20,  8.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6352, acc = 64.36%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 56%|█████▌    | 56/100 [07:59<06:11,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6959, acc = 65.62%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 57%|█████▋    | 57/100 [08:08<06:03,  8.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6679, acc = 63.79%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 58%|█████▊    | 58/100 [08:16<05:55,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6383, acc = 65.34%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 59%|█████▉    | 59/100 [08:25<05:48,  8.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6519, acc = 65.67%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 60%|██████    | 60/100 [08:33<05:39,  8.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6980, acc = 64.50%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 61%|██████    | 61/100 [08:41<05:30,  8.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6810, acc = 65.63%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 62%|██████▏   | 62/100 [08:50<05:25,  8.57s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6530, acc = 65.54%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 63%|██████▎   | 63/100 [08:59<05:16,  8.56s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7008, acc = 65.11%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 64%|██████▍   | 64/100 [09:07<05:06,  8.52s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6589, acc = 65.37%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 65%|██████▌   | 65/100 [09:16<04:57,  8.51s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6742, acc = 65.31%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 66%|██████▌   | 66/100 [09:24<04:48,  8.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7466, acc = 63.89%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 67%|██████▋   | 67/100 [09:33<04:40,  8.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7226, acc = 64.51%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 68%|██████▊   | 68/100 [09:41<04:31,  8.50s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7175, acc = 65.79%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 69%|██████▉   | 69/100 [09:50<04:22,  8.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6867, acc = 65.19%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 70%|███████   | 70/100 [09:58<04:14,  8.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6758, acc = 65.02%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 71%|███████   | 71/100 [10:07<04:05,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6835, acc = 65.79%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 72%|███████▏  | 72/100 [10:15<03:57,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6955, acc = 64.72%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 73%|███████▎  | 73/100 [10:23<03:48,  8.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7092, acc = 65.17%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 74%|███████▍  | 74/100 [10:32<03:39,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7160, acc = 64.91%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|███████▌  | 75/100 [10:40<03:31,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7359, acc = 64.78%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 76%|███████▌  | 76/100 [10:49<03:22,  8.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7093, acc = 65.34%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 77%|███████▋  | 77/100 [10:57<03:14,  8.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7187, acc = 65.02%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 78%|███████▊  | 78/100 [11:06<03:06,  8.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7543, acc = 65.27%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 79%|███████▉  | 79/100 [11:14<02:56,  8.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.6933, acc = 65.84%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 80%|████████  | 80/100 [11:22<02:47,  8.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7214, acc = 65.96%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 81%|████████  | 81/100 [11:30<02:37,  8.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7268, acc = 66.03%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 82%|████████▏ | 82/100 [11:39<02:29,  8.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7710, acc = 64.63%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 83%|████████▎ | 83/100 [11:47<02:20,  8.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7067, acc = 65.81%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 84%|████████▍ | 84/100 [11:55<02:12,  8.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7167, acc = 65.63%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 85%|████████▌ | 85/100 [12:04<02:04,  8.33s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7859, acc = 64.21%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 86%|████████▌ | 86/100 [12:12<01:57,  8.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7156, acc = 65.21%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 87%|████████▋ | 87/100 [12:21<01:49,  8.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7345, acc = 66.02%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 88%|████████▊ | 88/100 [12:29<01:40,  8.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7392, acc = 66.21%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 89%|████████▉ | 89/100 [12:38<01:32,  8.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7580, acc = 65.42%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 90%|█████████ | 90/100 [12:46<01:24,  8.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7173, acc = 65.67%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 91%|█████████ | 91/100 [12:54<01:15,  8.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7316, acc = 64.99%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 92%|█████████▏| 92/100 [13:03<01:07,  8.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7272, acc = 65.91%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 93%|█████████▎| 93/100 [13:11<00:59,  8.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7680, acc = 64.49%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 94%|█████████▍| 94/100 [13:20<00:50,  8.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.8080, acc = 65.44%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 95%|█████████▌| 95/100 [13:28<00:42,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.8386, acc = 64.52%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 96%|█████████▌| 96/100 [13:37<00:33,  8.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7521, acc = 65.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 97%|█████████▋| 97/100 [13:45<00:25,  8.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7555, acc = 64.17%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 98%|█████████▊| 98/100 [13:54<00:16,  8.48s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7668, acc = 65.08%\n"],"name":"stdout"},{"output_type":"stream","text":["\r 99%|█████████▉| 99/100 [14:02<00:08,  8.57s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7395, acc = 65.67%\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 100/100 [14:11<00:00,  8.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["loss = 1.7442, acc = 66.00%\n","loss = 1.7442, acc = 66.00%\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KXwXYkGoFaFz","colab_type":"code","outputId":"ea19686a-bc1f-42e0-fb5d-2b85c502f62b","executionInfo":{"status":"ok","timestamp":1560685719445,"user_tz":-540,"elapsed":878687,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["plt.plot(np.arange(0, len(train_loss), 1), train_loss)\n","plt.plot(np.arange(0, len(valid_loss), 1), valid_loss)\n","plt.show() # train과 validation 모두 봐야 한다."],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"tppzG1VKq6kj","colab_type":"text"},"source":["## Model B : Build  --> Model A와 동일한 Structure이고, Optimizer만 Momentum으로 변경함"]},{"cell_type":"code","metadata":{"id":"SVMczcqNq6Np","colab_type":"code","outputId":"91162966-19a6-46c5-fbfc-09d2895a770c","executionInfo":{"status":"ok","timestamp":1560665891211,"user_tz":-540,"elapsed":916,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["graph = tf.Graph()\n","with graph.as_default() :\n","    xs = tf.placeholder(tf.float32, (None, 32, 32, 3), name='xs') # 32*32 = 1024\n","    ys = tf.placeholder(tf.int32, (None), name='ys')\n","    lr = tf.placeholder_with_default(0.001, (), name='lr')\n","    \n","    with tf.name_scope('convolution_layer_1') :   ## filters is number of channels\n","        kernel_init = tf.random.normal(shape=[2, 2, 3, 16], mean=0.0, stddev=0.1, dtype=tf.float32, name='kernel_init') # random normal \n","        kernel= tf.Variable(kernel_init, name='kernel')               \n","        bias_init = tf.zeros([16])\n","        bias = tf.Variable(bias_init, name='bias')\n","    \n","        layer = tf.nn.conv2d(xs, kernel, strides=[1,1,1,1], padding='SAME') # convolution and add bias\n","        layer = layer + bias\n","        layer = tf.nn.relu(layer)\n","        \n","        pool = tf.layers.MaxPooling2D(pool_size=[2,2], strides=[2,2])(layer)\n","\n","    with tf.name_scope('convolution_layer_2') :   ## filters is number of channels\n","        kernel_init = tf.random.normal(shape=[2, 2, 16, 32], mean=0.0, stddev=0.1, dtype=tf.float32, name='kernel_init') # random normal \n","        kernel= tf.Variable(kernel_init, name='kernel')               \n","        bias_init = tf.zeros([32])\n","        bias = tf.Variable(bias_init, name='bias')\n","    \n","        layer = tf.nn.conv2d(pool, kernel, strides=[1,1,1,1], padding='SAME') # convolution and add bias   \n","        layer = layer + bias\n","        layer = tf.nn.relu(layer)\n","           \n","        pool = tf.layers.MaxPooling2D(pool_size=[2,2], strides=[2,2])(layer)\n","        \n","            \n","    with tf.name_scope('convolution_layer_3') :   ## filters is number of channels\n","        kernel_init = tf.random.normal(shape=[3, 3, 32, 64], mean=0.0, stddev=0.1, dtype=tf.float32, name='kernel_init') # random normal \n","        kernel= tf.Variable(kernel_init, name='kernel')               \n","        bias_init = tf.zeros([64])\n","        bias = tf.Variable(bias_init, name='bias')    \n","        layer = tf.nn.conv2d(pool, kernel, strides=[1,1,1,1], padding='SAME') # convolution and add bias       \n","        layer = layer + bias\n","        layer = tf.nn.relu(layer)\n","\n","        kernel_init2 = tf.random.normal(shape=[3, 3, 64, 64], mean=0.0, stddev=0.1, dtype=tf.float32, name='kernel_init') # random normal \n","        kernel2= tf.Variable(kernel_init2, name='kernel')               \n","        bias_init2 = tf.zeros([64])\n","        bias2 = tf.Variable(bias_init2, name='bias')    \n","        layer = tf.nn.conv2d(layer, kernel2, strides=[1,1,1,1], padding='SAME') # convolution and add bias   \n","        layer = layer + bias2\n","        layer = tf.nn.relu(layer)\n","    \n","        pool = tf.layers.MaxPooling2D(pool_size=[2,2], strides=[2,2])(layer)        \n","        \n","    # receptive filed = 27, images size = 32, output imagesize = (4, 4)\n","    \n","    with tf.name_scope('Reconstruct') : \n","        flatten = tf.layers.flatten(pool)\n","        layer = tf.layers.Dense(1024, activation=tf.nn.relu)(flatten) # 32*32\n","        layer = tf.layers.Dense(1024, activation=tf.nn.relu)(layer)\n","        y_pred = tf.layers.Dense(10, activation=None, name='y_pred')(layer)\n","        \n","    with tf.name_scope('Loss') :\n","        loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=ys, logits=y_pred))\n","        print(loss.shape)\n","        \n","    with tf.name_scope('metric') :\n","        rmse = tf.sqrt(loss)\n","    \n","    with tf.name_scope('accuracy') :\n","        pred = tf.cast(tf.arg_max(y_pred, 1), tf.int32)\n","        correct = tf.equal(pred, ys)\n","        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n","        \n","        # add tensor to tensorboard\n","        acc_tb = tf.summary.scalar(name='accuracy', tensor=accuracy)\n","\n","    with tf.name_scope('train') :\n","        train_op = tf.train.MomentumOptimizer(lr, momentum=0.9, use_nesterov=False).minimize(loss)\n","        #train_op = tf.train.AdamOptimizer(lr).minimize(loss)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["()\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Nyn0SDbfrGRV","colab_type":"text"},"source":["## Model B : Train"]},{"cell_type":"markdown","metadata":{"id":"G0hYYOQxyonM","colab_type":"text"},"source":["### Load trained weight and bias"]},{"cell_type":"code","metadata":{"id":"0YTr5PuHZaK3","colab_type":"code","colab":{}},"source":["from tensorflow.python.training import checkpoint_utils as cp\n","\n","# 변수 불러오기\n","# print('저장된 변수의 이름을 불러옵니다')\n","var_names = cp.list_variables('./model/vgg_net')   # 변수와 shape를 가져온다. 저장된 data와 index에서 가져온다.\n","#print('저장된 변수의 이름 {}'.format(var_names))\n","\n","# 값 불러오기\n","con_layer1_kernel  = cp.load_variable('./model/vgg_net' , 'convolution_layer_1/kernel')   \n","con_layer1_bias    = cp.load_variable('./model/vgg_net' , 'convolution_layer_1/bias')\n","\n","con_layer2_kernel  = cp.load_variable('./model/vgg_net' , 'convolution_layer_2/kernel')   \n","con_layer2_bias    = cp.load_variable('./model/vgg_net' , 'convolution_layer_2/bias')\n","\n","con_layer3_kernel1 = cp.load_variable('./model/vgg_net' , 'convolution_layer_3/kernel')   \n","con_layer3_bias1   = cp.load_variable('./model/vgg_net' , 'convolution_layer_3/bias')\n","con_layer3_kernel2 = cp.load_variable('./model/vgg_net' , 'convolution_layer_3/kernel_1')   \n","con_layer3_bias2   = cp.load_variable('./model/vgg_net' , 'convolution_layer_3/bias_1')\n","\n","# print('con_layer1, kernel : {} bias : {}'.format(con_layer1_kernel[:1,:1,:1], con_layer1_bias[0]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jTazVoc9zcd3","colab_type":"text"},"source":["## Model B : Train"]},{"cell_type":"code","metadata":{"id":"ZEShi1e3zefJ","colab_type":"code","outputId":"959bfda6-9730-4747-b857-468d0ae5e857","executionInfo":{"status":"error","timestamp":1560665909059,"user_tz":-540,"elapsed":15483,"user":{"displayName":"황인선","photoUrl":"","userId":"02350663787870167266"}},"colab":{"base_uri":"https://localhost:8080/","height":3385}},"source":["with graph.as_default() :\n","    \n","    # 텐서보드에 연결합니다. # sess.run보다 먼저 선언해야함. \n","    log_dir = \"./log/vgg_net\"    \n","    tbc = tensorboardcolab.TensorBoardColab(graph_path = log_dir)\n","    \n","    train_writer = tf.summary.FileWriter(logdir = log_dir)\n","    train_writer.add_graph(tf.get_default_graph())\n","    merged_all = tf.summary.merge_all()    \n","    \n","    sess = tf.Session()\n","    # weight를 불러왔기 때문에 초기화를 하면 안됨!\n","    # sess.run(tf.global_variables_initializer()) \n","    \n","    # Step2 : 기록\n","    saver = tf.train.Saver()\n","    \n","    # loading parameters\n","    saver.restore(sess, save_path='./model/vgg_net')\n","    # convolution_layer_1/kernel/Momentum <-- 얘를 초기화 하지 못함\n","    \n","    # Training\n","    batch_size = 30\n","    n_epoch = 2\n","    n_step = int(len(x_train) // batch_size)  # //은 몫이다.\n","    learing_rate = 0.0001\n","    \n","    # instance 생성\n","    train_generator = cifar_generator(x_train, y_train_label, batch_size)\n","    \n","    train_loss = []\n","    valid_loss = []\n","    valid_acc = []\n","    cnt = 0\n","    \n","    \n","    # Weight가 정상적으로 loading되었는지 확인함\n","    loss_, acc_ = sess.run([rmse, accuracy], feed_dict = { xs: x_validation, \n","                                                           ys: y_validation_label})\n","    print(\"\\n불러온 정보 확인! --> loss = {:.4f}, acc = {:.2f}%\\n\".format(loss_, acc_*100))\n","    \n","    print(\"Model B Train시작!\\n\")\n","    for i in tqdm(range(n_epoch)) :\n","        for step in range(n_step) :\n","            batch_xs, batch_ys = next(train_generator)\n","            _, train_loss_, tbs_train_ = sess.run([train_op, rmse, merged_all], feed_dict = { xs: batch_xs, \n","                                                                                              ys: batch_ys, \n","                                                                                              lr: learing_rate})\n","            train_writer.add_summary(tbs_train_, global_step=cnt) # 흠 되야 하는데 안된다.\n","            cnt += 1\n","            train_loss.append(train_loss_)\n","            if step % 100 == 0 :\n","                loss_, acc_ = sess.run([rmse, accuracy], feed_dict = { xs: x_validation, \n","                                                                       ys: y_validation_label})\n","                valid_loss.append(loss_)\n","                valid_acc.append(acc_)\n","    print(\"loss = {:.4f}, acc = {:.2f}%\".format(loss_, acc_*100))\n","\n","    saver.save(sess, save_path='./model/vgg_net')\n","    \n","    train_writer.flush() # file을 disk에 쓴다"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","https://cb18731d.ngrok.io\n"],"name":"stdout"},{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key convolution_layer_1/kernel/Momentum not found in checkpoint\n\t [[{{node save/RestoreV2}}]]\n  (1) Not found: Key convolution_layer_1/kernel/Momentum not found in checkpoint\n\t [[{{node save/RestoreV2}}]]\n\t [[save/RestoreV2/_15]]\n0 successful operations.\n0 derived errors ignored.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1286\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key convolution_layer_1/kernel/Momentum not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-15-e3eaae029e33>:16) ]]\n  (1) Not found: Key convolution_layer_1/kernel/Momentum not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-15-e3eaae029e33>:16) ]]\n\t [[save/RestoreV2/_15]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-e3eaae029e33>\", line 16, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 825, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1295\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m   \u001b[0mobject_graph_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader_GetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-e3eaae029e33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# loading parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./model/vgg_net'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# convolution_layer_1/kernel/Momentum <-- 얘를 초기화 하지 못함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1302\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\n2 root error(s) found.\n  (0) Not found: Key convolution_layer_1/kernel/Momentum not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-15-e3eaae029e33>:16) ]]\n  (1) Not found: Key convolution_layer_1/kernel/Momentum not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-15-e3eaae029e33>:16) ]]\n\t [[save/RestoreV2/_15]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-e3eaae029e33>\", line 16, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 825, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 837, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 875, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"]}]},{"cell_type":"code","metadata":{"id":"9y81GK9E5vo_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}