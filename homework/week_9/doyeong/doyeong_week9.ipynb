{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "doyeong_week9.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msn5sA5XjB-H",
        "colab_type": "text"
      },
      "source": [
        "* 최소한 weights를 저장하기 전에 모든 코드실행을 한 후에 제출하고 싶었으나  Training을 할 때 문제가 발생했습니다.\n",
        "* 코칭시간에 가서 해결을 해야 할 것 같습니다.\n",
        "* tensorboard에 tensor를 추가할 때 문제가 생기는 것 같습니다.\n",
        "* 빈칸을 넣는데에 시간을 굉장히 많이 썼습니다. 수업시간에 한 코드와 약간은 상이해서 난관이 많았습니다.\n",
        "* 일단 training을 하는 과정에서 saver를 이용해 min validation model을 저장하고 불러온 후 min loss와 같은 값을 보이는 지 확인해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V5DbTV6Y8_fm"
      },
      "source": [
        "## CIFAR-10, 100 학습시키기\n",
        "\n",
        "## Objective\n",
        "\n",
        "1.[CIFAR -10 Data](https://www.cs.toronto.edu/~kriz/cifar.html) 을 Convolution Neural Network 을 이용해 학습해봅니다.\n",
        "----\n",
        "![Imgur](https://i.imgur.com/yy09iLz.png)\n",
        "\n",
        "\n",
        "- loss 가 가장 작은 model 을 저장합니다.\n",
        "- 목표 accuracy 는 75% 입니다. \n",
        "​\n",
        "\n",
        "------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-syRx_WBWebm",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "okPBT4DkqPmu"
      },
      "source": [
        "# Load Cifar-10 dataset \n",
        " - cifar 10 dataset 을 다운로드 합니다. \n",
        " - normalize 을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ApD4EzRiqOGj",
        "outputId": "a111b308-d163-4e75-c890-9805863faf88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "# load cifar10 dataset \n",
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# reshape (None, 1) -> (None)\n",
        "y_train, y_test = [y.reshape([-1]) for y in (y_train, y_test)]\n",
        "\n",
        "# normalization \n",
        "x_train, x_test = [x /255. for x in (x_train, x_test)]\n",
        "\n",
        "# N class\n",
        "n_classes = 10\n",
        "print('image shape : {}, label shape : {} '.format(x_train.shape, y_train.shape))\n",
        "print('image shape : {}, label shape : {} '.format(x_test.shape, y_test.shape))\n",
        "print('train minimun : {}, train_maximum : {} '.format(x_train.min(), x_train.max()))\n",
        "print('tests minimun : {}, test_maximum : {} '.format(x_test.min(), x_test.max()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "image shape : (50000, 32, 32, 3), label shape : (50000,) \n",
            "image shape : (10000, 32, 32, 3), label shape : (10000,) \n",
            "train minimun : 0.0, train_maximum : 1.0 \n",
            "tests minimun : 0.0, test_maximum : 1.0 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inb-_UZEUQ_N",
        "colab_type": "text"
      },
      "source": [
        "# DataProvider "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JmE4_GikBI6I",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class DataProvider(object):\n",
        "    def __init__(self, images, labels):\n",
        "        self.n_sample = len(labels)\n",
        "        self.queue = list(range(self.n_sample))\n",
        "        random.shuffle(self.queue)\n",
        "\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.epoch_count = 0\n",
        "\n",
        "    def next_batch(self, batch_size):\n",
        "        if len(self.queue) < batch_size:\n",
        "            self.queue = list(range(self.n_sample))\n",
        "            self.epoch_count += 1\n",
        "        target_indices = self.queue[:batch_size]\n",
        "        del self.queue[:batch_size]\n",
        "        return self.images[target_indices], self.labels[target_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b0Hku8a98_fo"
      },
      "source": [
        "# Configuration\n",
        "\n",
        "설계한 모델을 표로 작성합니다. \n",
        "\n",
        "- 목표 Receptive Field : ? <br>\n",
        "- Convolution Phase 후  출력 크기  :  ? <br>\n",
        "\n",
        "\n",
        "| 층  | 종류|필터 갯수  | 필터 크기 | 스트라이드 | 패딩   | Dropout | output size |\n",
        "|--- |--- |----|----|----|----|----| ---| \n",
        "| ? |?| ?|? |?  | ? |?| ?|\n",
        "\n",
        "\n",
        "- 모델 설계가 끝나면 간단한 그림을 작성해 아래에 붙여주세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDhKG-rSUQ_P",
        "colab_type": "text"
      },
      "source": [
        "예시1) \n",
        "\n",
        "\n",
        "- 목표 Receptive Field : 28 <br>\n",
        "- Convolution Phase 후  출력 크기  :  4 <br>\n",
        "- Regularization  : L2 \n",
        "- Batch size : 120\n",
        "- Learning rate : 0.0001 \n",
        "- Data normalization : min max normalization \n",
        "- Standardization : None \n",
        "\n",
        "\n",
        "| 층  | 종류|필터 갯수  | 필터 크기 | 스트라이드 | 패딩   | Dropout | output size |\n",
        "|--- |--- |----|----|----|----|----| ---| \n",
        "| c1 |conv| 64| 3x3| 1  | SAME | None| 32x32 |\n",
        "| s2 |max-pooling| None| 3x3| 2  | SAME | None|16x16 | \n",
        "| c3 |conv| 128| 3x3| 2  | SAME |NOne |16x16 | \n",
        "| s4 |max-pooling| None| 3x3| 2  | SAME | None|8 x8 | \n",
        "| c5 |conv| 128| 3x3| 2  | SAME | None |8 x8 | \n",
        "| s6 |conv| 256| 3x3| 2  | SAME | None |4 x 4 | \n",
        "| c7 |conv| 256| 1x1| 2  | SAME | None |4 x 4 | \n",
        "| f8 ||| | FC 256  | |  || \n",
        "| f8 ||| | Dropout 0.7 | |  || \n",
        "| f9 ||| | FC 256  | |  || \n",
        "| f9 ||| | Dropout 0.6 | |  || \n",
        "| f10||| | FC 10   | |  || \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![Imgur](https://i.imgur.com/yqrIm5u.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu2qtnd7UQ_Q",
        "colab_type": "text"
      },
      "source": [
        "# Convolution layer\n",
        "- convolution layer helper function 을 정의합니다.\n",
        "- 위 설계한 convolution layer 을 구현합니다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rzr0by6Kyv6J",
        "colab": {}
      },
      "source": [
        "# convolution helper function\n",
        "def conv(input_xs ,units, k, s, padding, activation, name):\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        ch = int(input_xs.get_shape()[3])\n",
        "        ws = tf.get_variable(name='ws', shape=[k,k,ch,units], dtype=tf.float32, initializer=tf.initializers.he_normal())\n",
        "        b = tf.get_variable(name='bias', initializer=tf.zeros(shape=[units], dtype=tf.float32))\n",
        "        layer = tf.nn.conv2d(input_xs, ws, [1,s,s,1], padding=padding, name='conv') + b\n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AJcmfqHJ9lLm",
        "colab": {}
      },
      "source": [
        "# define input placeholder \n",
        "xs = tf.placeholder(shape=[None, 32, 32, 3], dtype=tf.float32, name='xs')\n",
        "ys = tf.placeholder(shape=[None], dtype=tf.int32, name='ys')\n",
        "lr = tf.placeholder(shape=[], dtype=tf.float32, name='lr')\n",
        "phase_train = tf.placeholder(shape=[], dtype=tf.bool, name='phase_train')\n",
        "\n",
        "# Model implementation \n",
        "# convolution Neural Network \n",
        "# 자신이 설계한 모형을 구현해주세요. \n",
        "layer1 = conv(xs, units=8, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_1')\n",
        "layer2 = conv(layer1, units=8, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_2')\n",
        "max_pool1 = tf.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), name='maxpool_1')(layer2)\n",
        "\n",
        "layer3 = conv(max_pool1, units=16, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_3')\n",
        "layer4 = conv(layer3, units=16, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_4')\n",
        "max_pool2 = tf.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), name='maxpool_2')(layer4)\n",
        "\n",
        "layer5 = conv(max_pool2, units=32, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_5')\n",
        "layer6 = conv(layer5, units=32, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_6')\n",
        "layer7 = conv(layer6, units=32, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_7')\n",
        "max_pool3 = tf.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), name='maxpool_3')(layer7)\n",
        "\n",
        "layer8 = conv(max_pool3, units=64, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_8')\n",
        "layer9 = conv(layer8, units=64, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_9')\n",
        "layer10 = conv(layer9, units=64, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_10')\n",
        "max_pool4 = tf.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), name='maxpool_4')(layer10)\n",
        "\n",
        "layer11 = conv(max_pool4, units=128, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_11')\n",
        "layer12 = conv(layer11, units=128, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_12')\n",
        "layer13 = conv(layer12, units=128, k=3, s=1, padding='SAME', activation=tf.nn.relu, name='layer_13')\n",
        "max_pool5 = tf.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), name='maxpool_5')(layer13)\n",
        "\n",
        "top_conv = tf.identity(max_pool5, 'top_conv') # 마지막 layer 을 top conv 에 넣습니다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRukJjRZUQ_V",
        "colab_type": "text"
      },
      "source": [
        "# Fully Connected Layer\n",
        "- 설계한 fully connected layer 을 구현합니다.\n",
        "- dropout 을 적용합니다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woNx29qxUQ_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fc(flat_layer, units, activation, initializer, layer_name):\n",
        "    n_input = int(flat_layer.get_shape()[-1])\n",
        "    with tf.variable_scope(layer_name, reuse=tf.AUTO_REUSE):\n",
        "        w = tf.get_variable(name='w', shape=[n_input, units], initializer=initializer())\n",
        "        b = tf.get_variable(name='b', shape=[units], initializer=tf.initializers.constant(value=0, dtype=tf.float32))\n",
        "        layer = tf.matmul(flat_layer, w) + b\n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fL1M4gvUQ_X",
        "colab_type": "code",
        "outputId": "729299d2-99e2-4ec5-a080-9095fbef2a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "# flat layer \n",
        "flat_layer = tf.layers.flatten(top_conv)\n",
        "\n",
        "# fully connected layer 1\n",
        "fc_initalizer = tf.initializers.he_normal()\n",
        "fc_layer_1 = fc(flat_layer, 512, tf.nn.relu, tf.initializers.he_normal, 'fc1')\n",
        "fc_layer_1 = tf.layers.dropout(fc_layer_1, training=phase_train, rate=0.5)\n",
        "\n",
        "fc_layer_2 = fc(fc_layer_1, 512, tf.nn.relu, tf.initializers.he_normal, 'fc2')\n",
        "fc_layer_2 = tf.layers.dropout(fc_layer_2, training=phase_train, rate=0.5)\n",
        "\n",
        "fc_layer_3 = fc(fc_layer_2, 10, None, tf.initializers.glorot_normal, 'fc3')\n",
        "logits= tf.identity(fc_layer_3, 'logits')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0616 11:37:21.352409 139677661910912 deprecation.py:323] From <ipython-input-7-0f18bd428d96>:1: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0616 11:37:21.621757 139677661910912 deprecation.py:506] From <ipython-input-6-40e69d0e0264>:5: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0616 11:37:21.632240 139677661910912 deprecation.py:323] From <ipython-input-7-0f18bd428d96>:6: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "W0616 11:37:21.761134 139677661910912 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-625ULtUQ_Z",
        "colab_type": "text"
      },
      "source": [
        "#  Loss function \n",
        "- loss function 을 정의합니다. L2 regularization 을 사용합니다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ2DkXG-UQ_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l2_reg = tf.reduce_sum([tf.nn.l2_loss(var) for var in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)])\n",
        "l2_beta = 0.01\n",
        "\n",
        "#loss \n",
        "# L2 regularization \n",
        "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=ys, logits=logits)\n",
        "loss = tf.reduce_mean(loss, name='loss') + l2_reg*l2_beta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_Oke8OgUQ_e",
        "colab_type": "text"
      },
      "source": [
        "# Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-_TMXVtX1pXK",
        "colab": {}
      },
      "source": [
        "# metric\n",
        "logits_cls = tf.argmax(logits, axis=1)\n",
        "logits_cls = tf.cast(logits_cls, dtype=tf.int32)\n",
        "acc = tf.metrics.accuracy(labels=ys, predictions=logits_cls, name='accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obfoWSrLUQ_h",
        "colab_type": "text"
      },
      "source": [
        "# Add tensor to Tensorboard "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqUXVsUTUQ_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add accuracy to tensorboard nodes \n",
        "tf.summary.scalar(name='accuracy', tensor=acc)\n",
        "\n",
        "# add loss to tensorboard nodes \n",
        "tf.summary.scalar(name='loss', tensor=loss)\n",
        "\n",
        "#merge all tensorboard nodes \n",
        "merged = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGeaVRCOUQ_j",
        "colab_type": "text"
      },
      "source": [
        "# Optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83C5s7mfUQ_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_op : adamoptimizer \n",
        "train_op = tf.train.AdamOptimizer(lr).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6N1fBH2BBfX6"
      },
      "source": [
        "# Session open "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wiz-2rkLBdTw",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "\n",
        "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())# : globalal initializer \n",
        "sess.run(init)\n",
        "\n",
        "# saver \n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFmQDdJDUQ_o",
        "colab_type": "text"
      },
      "source": [
        "# Tensorboard Filewriter "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPH7CLomUQ_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorboard \n",
        "train_writer=tf.summary.FileWriter(logdir='./log/train')\n",
        "test_writer=tf.summary.FileWriter(logdir='./log/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P88ef2rRUQ_q",
        "colab_type": "text"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yv99AR4A_Y7P",
        "scrolled": true,
        "outputId": "9c7973e8-e95e-49b7-a765-5331109384c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1425
        }
      },
      "source": [
        "dataprovider = DataProvider(images=x_train, labels=y_train)\n",
        "# save_root_folder = #fix me # : models saved folder \n",
        "\n",
        "# hparam \n",
        "batch_size = 100\n",
        "min_loss = 1000000.0\n",
        "learning_rate = 0.0005\n",
        "\n",
        "for i in range(10000):\n",
        "    batch_xs, batch_ys = dataprovider.next_batch(batch_size)\n",
        "    # training \n",
        "    _ = sess.run(train_op, feed_dict={xs: batch_xs, ys: batch_ys, lr: learning_rate, phase_train: True})\n",
        "    \n",
        "    if i % 100 == 0 :\n",
        "        # Validate validation dataset \n",
        "        fetches=[loss, acc, merged]\n",
        "        val_loss, val_acc, val_merged = sess.run(fetches, feed_dict={xs: x_test, ys: y_test, phase_train: False})\n",
        "\n",
        "        # Validate train dataset : extract randomly 10000 samples from train dataset \n",
        "        batch_xs, batch_ys = dataprovider.next_batch(10000)\n",
        "        train_loss, train_acc, train_merged = sess.run(fetches, feed_dict={xs: batch_xs, ys: batch_ys, phase_train: False})\n",
        "        \n",
        "        print('step : {} train loss : {:.4f} acc : {:.4f} | Val loss : {:.4f} acc : {:.4f}'.\\\n",
        "        format(i, train_loss, train_acc, val_loss, val_acc))\n",
        "\n",
        "#         # Save Model \n",
        "#         if #fix me # : when val_loss < min_loss \n",
        "#             min_loss = val_loss\n",
        "#             save_path = #fix me #\n",
        "#             saver.save(#fix me#)\n",
        "#             print('model save!')\n",
        "            \n",
        "        # Add values to tensorboard \n",
        "        train_writer.add_summary(summary=train_merged, global_step=i)\n",
        "        test_writer.add_summary(summary=val_merged, global_step=i)\n",
        "        train_writer.flush()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: tags and values not the same shape: [] != [2] (tag 'accuracy_1')\n\t [[{{node accuracy_1}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-10e1809a0b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Validate validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfetches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Validate train dataset : extract randomly 10000 samples from train dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: tags and values not the same shape: [] != [2] (tag 'accuracy_1')\n\t [[node accuracy_1 (defined at <ipython-input-10-58f0867e0879>:1) ]]\n\nOriginal stack trace for 'accuracy_1':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-58f0867e0879>\", line 1, in <module>\n    tf.summary.scalar(name='accuracy', tensor=acc)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/summary/summary.py\", line 82, in scalar\n    val = _gen_logging_ops.scalar_summary(tags=tag, values=tensor, name=scope)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_logging_ops.py\", line 777, in scalar_summary\n    \"ScalarSummary\", tags=tags, values=values, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3IzIVKHoYgiV"
      },
      "source": [
        "<hr>\n",
        "<div style = \"background-image: url('https://algorithmai.io/static/media/logo.665798c4.png');background-repeat: no-repeat; background-position: right; background-size: 220px 40px; padding : 5px 10px 5px 5px;\">\n",
        "    Copyright(c) 2019 by Public AI. All rights reserved.<br>\n",
        "    Writen by PAI, SangJae Kang ( rocketgrowthsj@publicai.co.kr )  last updated on 2019/06/17\n",
        "</div>\n",
        "<hr>"
      ]
    }
  ]
}