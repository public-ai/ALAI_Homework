{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "문_4_Mini Batch SGD",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V5DbTV6Y8_fm"
      },
      "source": [
        "# Section 4_Mini Batch SGD\n",
        "\n",
        "### Objective\n",
        "1. **데이터를 추출하는 여러가지 방법을 통해 DNN 모델의 성능을 개선시키는 법을 배워봅니다**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "k0tlZXNK7JNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "734ca411-40b2-4335-f871-4929111cb033"
      },
      "source": [
        "!pip install emnist\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "from emnist import extract_training_samples\n",
        "from emnist import extract_test_samples\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emnist\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/f4/78b24acbef9e8fe976dda700f16a3606f3b8363b015bc555f8050fbbd8ac/emnist-0.0-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from emnist) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from emnist) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from emnist) (1.16.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->emnist) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->emnist) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->emnist) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->emnist) (2019.3.9)\n",
            "Installing collected packages: emnist\n",
            "Successfully installed emnist-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPKmEmML7JOD",
        "colab_type": "text"
      },
      "source": [
        "### [Optional.  Tensorflow Graph Visualization ]\n",
        "\n",
        "---\n",
        "\n",
        "> _Jupyter에서 Tensorflow에서 구성되는 Graph를 시각적으로 보여주기 위한 helper 메소드입니다._<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX1mKwhc7JOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output, Image, display, HTML\n",
        "import numpy as np    \n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
        "    strip_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = strip_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        if n.op == 'Const':\n",
        "            tensor = n.attr['value'].tensor\n",
        "            size = len(tensor.tensor_content)\n",
        "            if size > max_const_size:\n",
        "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
        "    return strip_def\n",
        "\n",
        "def show_graph(graph_def, max_const_size=32):\n",
        "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
        "    if hasattr(graph_def, 'as_graph_def'):\n",
        "        graph_def = graph_def.as_graph_def()\n",
        "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
        "    code = \"\"\"\n",
        "        <script>\n",
        "          function load() {{\n",
        "            document.getElementById(\"{id}\").pbtxt = {data};\n",
        "          }}\n",
        "        </script>\n",
        "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "        <div style=\"height:600px\">\n",
        "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "        </div>\n",
        "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "\n",
        "    iframe = \"\"\"\n",
        "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "    \"\"\".format(code.replace('\"', '&quot;'))\n",
        "\n",
        "    display(HTML(iframe))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b0Hku8a98_fo"
      },
      "source": [
        "## 문제 1. DataProvider 구현해보기\n",
        "\n",
        "\n",
        "문제 설명 : \n",
        "numpy 을 이용해\n",
        "random 으로 데이터를 지정한 크기만큼 추출하는 코드를 구현해 봅니다. \n",
        "\n",
        "- 한번 추출한 데이터는 다음번 데이터를 추출할 때 을 때 보존되지 않습니다. (비 복원 추출)\n",
        "- 만약 지정한 batch size 보다 적은 데이터가 남아 있다면 데이터를 다시 섞고 처음부터 추출합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yJgMgkoRDJqa"
      },
      "source": [
        "#### 답안지 입력란\n",
        "* 아래에 답을 서술하여 주세요\n",
        "* `next_batch` 를 구현해 주세요. \n",
        "* `epoch_count`는 전체 데이터셋을 한번 반복하였을 때, 1씩 올라가게 됩니다.<br> next_batch를 반복해서 실행하면, epoch 별로 epoch_count가 1씩 올라가게됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDpC_gob7JOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataProvider(object):\n",
        "    def __init__(self, xs, ys):\n",
        "        self.ys = ys\n",
        "        self.xs = xs\n",
        "        self.ind_shuffle = np.arange(0, xs.shape[0])\n",
        "        self.xs_size = len(xs)\n",
        "        self.remain_size = self.xs_size\n",
        "        self.epoch_count = 0\n",
        "        np.random.shuffle(self.ind_shuffle)\n",
        "        self.xs_re = self.xs.copy()\n",
        "        self.ys_re = self.ys.copy()\n",
        "        self.xs = list(self.xs[self.ind_shuffle])\n",
        "        self.ys = list(self.ys[self.ind_shuffle])\n",
        "        \n",
        "    def next_batch(self, size):\n",
        "        self.size = size\n",
        "        if self.remain_size <= self.size :\n",
        "            out_xs = self.xs[:] #잔여 데이터 return함\n",
        "            out_ys = self.ys[:]\n",
        "            del(self.xs[:])\n",
        "            del(self.ys[:])\n",
        "            self.xs = self.xs_re.copy()\n",
        "            self.ys = self.ys_re.copy()\n",
        "            self.ind_shuffle2 = np.arange(0, self.xs.shape[0])\n",
        "            np.random.shuffle(self.ind_shuffle2)\n",
        "            self.xs = list(self.xs[self.ind_shuffle2])\n",
        "            self.ys = list(self.ys[self.ind_shuffle2])\n",
        "            self.epoch_count += 1\n",
        "            self.remain_size = self.xs_size\n",
        "        else :\n",
        "            out_xs = self.xs[:self.size]\n",
        "            out_ys = self.ys[:self.size]\n",
        "            del(self.xs[0:self.size])\n",
        "            del(self.ys[0:self.size])\n",
        "            self.remain_size -= self.size\n",
        "        return out_xs, out_ys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hayGOfpcC8Uq"
      },
      "source": [
        "#### 정답 확인\n",
        "* 정답을 입력한 후, 아래를 실행시키면 정답인지 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AxeeJ-W755-j",
        "outputId": "af665913-870d-4cbc-efd4-4c261ce0a733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "source": [
        "# 아래 코드를 수행해주세요. \n",
        "# 위에서 생성한 DataProvider instance 를 생성합니다 \n",
        "random.seed(0)\n",
        "xs = np.arange(0, 10)\n",
        "ys = np.arange(0, 10)\n",
        "dataprovider=DataProvider(xs, ys)\n",
        "\n",
        "# 4번 비복원 추출합니다.\n",
        "batch_xs1, batch_ys1 = dataprovider.next_batch(3)\n",
        "batch_xs2, batch_ys2 = dataprovider.next_batch(3)\n",
        "batch_xs3, batch_ys3 = dataprovider.next_batch(3)\n",
        "batch_xs4, batch_ys4 = dataprovider.next_batch(3)\n",
        "\n",
        "# 비복원 추출인지 아닌지를 판단합니다. \n",
        "batches_xs = np.concatenate([batch_xs1, batch_xs2, batch_xs3])\n",
        "batches_ys = np.concatenate([batch_ys1, batch_ys2, batch_ys3])\n",
        "\n",
        "if len(batches_xs) == 9 and len(batches_ys) == 9:\n",
        "    pass;\n",
        "else:\n",
        "    raise ValueError(\"비복원 추출이 아닙니다. 다시 확인해주세요.\")\n",
        "\n",
        "# random하게 추출하는지 아닌지를 판단합니다.. \n",
        "np.testing.assert_almost_equal(batch_xs1, np.array([7, 8, 1]),\n",
        "                               err_msg='next_batch 함수 설계가 잘못되었습니다. 아래를 참조해 다시 확인해주세요.')\n",
        "np.testing.assert_almost_equal(batch_ys1, np.array([7, 8, 1]),\n",
        "                               err_msg='next_batch 함수 설계가 잘못되었습니다. 아래를 참조해 다시 확인해주세요.')\n",
        "\n",
        "# random epoch counter 가 제대로 작동하지 않습니다. \n",
        "if dataprovider.epoch_count == 1:\n",
        "    print(\"정답입니다!!!!\")\n",
        "else:\n",
        "    raise ValueError(\"epoch_counter 가 제대로 작동하지 않습니다. 다시 확인해주세요.\")"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-5b0853998869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# random하게 추출하는지 아닌지를 판단합니다..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m np.testing.assert_almost_equal(batch_xs1, np.array([7, 8, 1]),\n\u001b[0;32m---> 23\u001b[0;31m                                err_msg='next_batch 함수 설계가 잘못되었습니다. 아래를 참조해 다시 확인해주세요.')\n\u001b[0m\u001b[1;32m     24\u001b[0m np.testing.assert_almost_equal(batch_ys1, np.array([7, 8, 1]),\n\u001b[1;32m     25\u001b[0m                                err_msg='next_batch 함수 설계가 잘못되었습니다. 아래를 참조해 다시 확인해주세요.')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_almost_equal\u001b[0;34m(actual, desired, decimal, err_msg, verbose)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0massert_array_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;31m# If one of desired/actual is not finite, handle it specially here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_almost_equal\u001b[0;34m(x, y, decimal, err_msg, verbose)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,\n\u001b[1;32m   1006\u001b[0m              \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Arrays are not almost equal to %d decimals'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m              precision=decimal)\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    817\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not almost equal to 7 decimals\nnext_batch 함수 설계가 잘못되었습니다. 아래를 참조해 다시 확인해주세요.\nMismatch: 100%\nMax absolute difference: 6\nMax relative difference: 6.\n x: array([4, 9, 7])\n y: array([7, 8, 1])"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "52f8GuvnYVCN"
      },
      "source": [
        "## 문제 2. Stochastic Batch 구현해보기\n",
        "\n",
        "\n",
        "문제 설명 :\n",
        "batch size 별로 Model의 accuracy , loss 을 비교해 봅니다.\n",
        "\n",
        "- batch size 가 1, 30, 60, 120  일 때 test dataset 에 대한 loss 와 accuracy 을 구해서 비교해 봅니다. \n",
        "- 총 20 epoch 을 수행합니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JVi6MdsNZs7T",
        "outputId": "5dee45b2-7d6b-421e-d0e1-d64bca79447b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "# 우선실행해 주세요!\n",
        "# Data load and preprocessing \n",
        "train_images, train_labels = extract_training_samples('letters')\n",
        "test_images, test_labels = extract_test_samples('letters')\n",
        "\n",
        "# images normalization\n",
        "train_images = train_images / 255.\n",
        "test_images = test_images / 255.\n",
        "\n",
        "# label normalization\n",
        "train_labels = train_labels.copy() -1\n",
        "test_labels = test_labels.copy() -1\n",
        "\n",
        "fig = plt.figure(figsize=(12,3))\n",
        "axes = fig.subplots(1,8)\n",
        "for image, ax in zip(train_images, axes):\n",
        "    ax.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "# images flatten\n",
        "train_images = np.reshape(train_images, [-1, 784])\n",
        "test_images = np.reshape(test_images, [-1, 784])\n",
        "\n",
        "n_classes = train_labels.max() + 1"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAABqCAYAAABZAFxNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 864x216 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azNQ9RZEWptP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "1be6d7e2-505f-4d75-ef55-5084dbd22313"
      },
      "source": [
        "print(train_labels.shape)\n",
        "print(type(train_labels))\n",
        "print(train_images.shape)\n",
        "plt.imshow(np.reshape(train_images[0], (28,28)))\n",
        "train_labels[0]"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(124800,)\n",
            "<class 'numpy.ndarray'>\n",
            "(124800, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEX4gUYQfSBThBxJF+IFE/T9DQ0CoiI/XCAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FeI9tSSV3JV8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "0d398a9d-e557-4024-f36b-af184a8ddae0"
      },
      "source": [
        "# 아래 코드를 먼저 수행해주세요.\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "    # input placeholder\n",
        "    xs = tf.placeholder(tf.float32, shape=[None, 28 * 28], name='xs')\n",
        "    ys = tf.placeholder(tf.int64, shape=[None,], name='ys')\n",
        "    lr = tf.placeholder_with_default(0.1,(),name='learning_rate')\n",
        "\n",
        "    he_init = tf.initializers.he_normal()\n",
        "    glorot_init = tf.initializers.glorot_normal()\n",
        "    \n",
        "    # Hidden Layer \n",
        "    h1 = tf.layers.Dense(64, activation=tf.nn.relu,\n",
        "                         kernel_initializer=he_init,name='dense-1')(xs)\n",
        "    h2 = tf.layers.Dense(128, activation=tf.nn.relu,\n",
        "                         kernel_initializer=he_init,name='dense-2')(h1)\n",
        "    h3 = tf.layers.Dense(256, activation=tf.nn.relu,\n",
        "                         kernel_initializer=he_init,name='dense-3')(h2)\n",
        "\n",
        "    # Logits Layer \n",
        "    logits = tf.layers.Dense(n_classes,kernel_initializer=glorot_init,\n",
        "                             name='logits')(h3)\n",
        "\n",
        "    # logits to prediction for multicalssification  \n",
        "    pred = tf.nn.softmax(logits, name='prediction')\n",
        "\n",
        "    # metric \n",
        "    with tf.variable_scope('metrics'):\n",
        "        acc = tf.reduce_mean(\n",
        "            tf.cast(tf.equal(tf.argmax(pred, axis=1), ys),tf.float32))\n",
        "    acc = tf.identity(acc,name='accuracy')\n",
        "        \n",
        "    # cross-entropy-loss\n",
        "    cee = tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=ys)\n",
        "    \n",
        "    # optimizer\n",
        "    train_op = (tf.train\n",
        "                .GradientDescentOptimizer(lr)\n",
        "                .minimize(cee))\n",
        "    \n",
        "show_graph(graph)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
              "        <script>\n",
              "          function load() {\n",
              "            document.getElementById(&quot;graph0.5704544016792719&quot;).pbtxt = 'node {\\n  name: &quot;xs&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ys&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;learning_rate/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;learning_rate&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;learning_rate/input&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/kernel/Initializer/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000@\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/kernel/Initializer/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/kernel/Initializer/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.05741945654153824\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/kernel/Initializer/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dense-1/kernel/Initializer/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/kernel/Initializer/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dense-1/kernel/Initializer/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dense-1/kernel/Initializer/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/kernel/Initializer/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dense-1/kernel/Initializer/truncated_normal/mul&quot;\\n  input: &quot;dense-1/kernel/Initializer/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dense-1/kernel&quot;\\n  input: &quot;dense-1/kernel/Initializer/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dense-1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dense-1/bias&quot;\\n  input: &quot;dense-1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dense-1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;xs&quot;\\n  input: &quot;dense-1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dense-1/MatMul&quot;\\n  input: &quot;dense-1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dense-1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/kernel/Initializer/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;@\\\\000\\\\000\\\\000\\\\200\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/kernel/Initializer/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/kernel/Initializer/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.20096810162067413\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/kernel/Initializer/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dense-2/kernel/Initializer/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/kernel/Initializer/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dense-2/kernel/Initializer/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dense-2/kernel/Initializer/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/kernel/Initializer/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dense-2/kernel/Initializer/truncated_normal/mul&quot;\\n  input: &quot;dense-2/kernel/Initializer/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 64\\n        }\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dense-2/kernel&quot;\\n  input: &quot;dense-2/kernel/Initializer/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dense-2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 128\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dense-2/bias&quot;\\n  input: &quot;dense-2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dense-2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dense-1/Relu&quot;\\n  input: &quot;dense-2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dense-2/MatMul&quot;\\n  input: &quot;dense-2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dense-2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/kernel/Initializer/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\200\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/kernel/Initializer/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/kernel/Initializer/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.14210590720176697\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/kernel/Initializer/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;dense-3/kernel/Initializer/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/kernel/Initializer/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dense-3/kernel/Initializer/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;dense-3/kernel/Initializer/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/kernel/Initializer/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dense-3/kernel/Initializer/truncated_normal/mul&quot;\\n  input: &quot;dense-3/kernel/Initializer/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n        dim {\\n          size: 256\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dense-3/kernel&quot;\\n  input: &quot;dense-3/kernel/Initializer/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dense-3/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 256\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 256\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;dense-3/bias&quot;\\n  input: &quot;dense-3/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;dense-3/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dense-2/Relu&quot;\\n  input: &quot;dense-3/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dense-3/MatMul&quot;\\n  input: &quot;dense-3/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dense-3/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dense-3/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/kernel/Initializer/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\001\\\\000\\\\000\\\\032\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/kernel/Initializer/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/kernel/Initializer/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.09573981165885925\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/kernel/Initializer/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;logits/kernel/Initializer/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/kernel/Initializer/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;logits/kernel/Initializer/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;logits/kernel/Initializer/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/kernel/Initializer/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;logits/kernel/Initializer/truncated_normal/mul&quot;\\n  input: &quot;logits/kernel/Initializer/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 256\\n        }\\n        dim {\\n          size: 26\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;logits/kernel&quot;\\n  input: &quot;logits/kernel/Initializer/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logits/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 26\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 26\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;logits/bias&quot;\\n  input: &quot;logits/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;logits/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dense-3/Relu&quot;\\n  input: &quot;logits/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;logits/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;logits/MatMul&quot;\\n  input: &quot;logits/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction&quot;\\n  op: &quot;Softmax&quot;\\n  input: &quot;logits/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;prediction&quot;\\n  input: &quot;metrics/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;metrics/ArgMax&quot;\\n  input: &quot;ys&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;metrics/Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;metrics/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;metrics/Cast&quot;\\n  input: &quot;metrics/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;accuracy&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;metrics/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/xentropy/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;ys&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/xentropy/xentropy&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;logits/BiasAdd&quot;\\n  input: &quot;ys&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/assert_broadcastable/weights/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/assert_broadcastable/weights/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/assert_broadcastable/values/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/xentropy/xentropy&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/assert_broadcastable/values/rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  op: &quot;NoOp&quot;\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/xentropy/xentropy&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/Mul&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/Equal/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/Const&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/Equal/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/ones_like/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/ones_like/Shape&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/Equal&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/zeros_like&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/weights/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/weights/rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/values/shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/xentropy/xentropy&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/values/rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/xentropy/xentropy&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Shape&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/Select&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights/ones_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/num_present&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/broadcast_weights&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/Const_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^sparse_softmax_cross_entropy_loss/assert_broadcastable/static_scalar_check_success&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/Sum&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sparse_softmax_cross_entropy_loss/value&quot;\\n  op: &quot;DivNoNan&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/Sum_1&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Shape&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/div_no_nan&quot;\\n  op: &quot;DivNoNan&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/div_no_nan&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Sum&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/div_no_nan_1&quot;\\n  op: &quot;DivNoNan&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/div_no_nan_2&quot;\\n  op: &quot;DivNoNan&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/div_no_nan_1&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/num_present&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/div_no_nan_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/mul&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Sum_1&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/sparse_softmax_cross_entropy_loss/value_grad/Reshape&quot;\\n  input: &quot;^gradients/sparse_softmax_cross_entropy_loss/value_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Reshape&quot;\\n  input: &quot;^gradients/sparse_softmax_cross_entropy_loss/value_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sparse_softmax_cross_entropy_loss/value_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/Reshape_1&quot;\\n  input: &quot;^gradients/sparse_softmax_cross_entropy_loss/value_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sparse_softmax_cross_entropy_loss/value_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_1_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/value_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_1_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_1_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_1_grad/Reshape&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_1_grad/Tile&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_grad/Reshape&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/xentropy/xentropy&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Shape&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_grad/Tile&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Mul&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Sum&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/xentropy/xentropy&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Sum_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Mul_1&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Sum_1&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Reshape&quot;\\n  input: &quot;^gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Reshape&quot;\\n  input: &quot;^gradients/sparse_softmax_cross_entropy_loss/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/sparse_softmax_cross_entropy_loss/Mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sparse_softmax_cross_entropy_loss/Mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/xentropy/xentropy:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;sparse_softmax_cross_entropy_loss/xentropy/xentropy:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/Mul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/ExpandDims&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logits/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logits/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/logits/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/mul&quot;\\n}\\nnode {\\n  name: &quot;gradients/logits/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/mul&quot;\\n  input: &quot;^gradients/logits/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logits/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logits/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/logits/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logits/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logits/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/logits/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;logits/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logits/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dense-3/Relu&quot;\\n  input: &quot;gradients/logits/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logits/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/logits/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/logits/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/logits/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logits/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/logits/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logits/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/logits/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/logits/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/logits/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/logits/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-3/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/logits/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dense-3/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-3/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dense-3/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-3/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dense-3/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dense-3/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dense-3/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-3/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dense-3/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-3/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-3/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dense-3/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-3/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-3/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dense-3/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;dense-3/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-3/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dense-2/Relu&quot;\\n  input: &quot;gradients/dense-3/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-3/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dense-3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dense-3/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dense-3/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dense-3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-3/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-3/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-3/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dense-3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-3/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dense-3/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dense-2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dense-2/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dense-2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dense-2/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dense-2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dense-2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dense-2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dense-2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;dense-2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dense-1/Relu&quot;\\n  input: &quot;gradients/dense-2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dense-2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dense-2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dense-2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dense-2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dense-2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dense-2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dense-1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dense-1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dense-1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dense-1/Relu_grad/ReluGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dense-1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dense-1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dense-1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dense-1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;dense-1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;xs&quot;\\n  input: &quot;gradients/dense-1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dense-1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dense-1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dense-1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dense-1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dense-1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dense-1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dense-1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dense-1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_dense-1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dense-1/kernel&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;gradients/dense-1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_dense-1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dense-1/bias&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;gradients/dense-1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_dense-2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dense-2/kernel&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;gradients/dense-2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_dense-2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dense-2/bias&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;gradients/dense-2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_dense-3/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dense-3/kernel&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;gradients/dense-3/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_dense-3/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;dense-3/bias&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;gradients/dense-3/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@dense-3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_logits/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;logits/kernel&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;gradients/logits/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_logits/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;logits/bias&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;gradients/logits/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@logits/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_dense-1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_dense-1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_dense-2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_dense-2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_dense-3/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_dense-3/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_logits/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_logits/kernel/ApplyGradientDescent&quot;\\n}\\n';\n",
              "          }\n",
              "        </script>\n",
              "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
              "        <div style=&quot;height:600px&quot;>\n",
              "          <tf-graph-basic id=&quot;graph0.5704544016792719&quot;></tf-graph-basic>\n",
              "        </div>\n",
              "    \"></iframe>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeyHMAyU7JPa",
        "colab_type": "text"
      },
      "source": [
        "#### 답안지 입력란\n",
        "* 아래에 답을 서술하여 주세요\n",
        "* 예제 1에서 작성한 코드와 위의 Graph를 이용해, 배치 사이즈 별로 어떻게 학습에서 차이가 나는지를 시각화 해주세요\n",
        "* 총 20epoch을 진행해주세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ERZV4fnl3XWC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5449
        },
        "outputId": "48f1aee0-b31c-45be-9095-be93e20fcf4c"
      },
      "source": [
        "batch_sizes = [1, 10, 60, 120]\n",
        "# 정답을 서술해 주세요\n",
        "loss_list = [[],[],[],[]]\n",
        "acc_list = [[],[],[],[]]\n",
        "for i_bat, batch_size in enumerate(batch_sizes) :\n",
        "    dataprovider = DataProvider(train_images, train_labels)\n",
        "    print(\"batch size : {}\".format(batch_size))\n",
        "    with tf.Session(graph = graph) as sess :\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        g1 = tf.get_default_graph()\n",
        "        acc = g1.get_tensor_by_name('accuracy:0')\n",
        "        cee = g1.get_collection(tf.GraphKeys.LOSSES)\n",
        "        for i in range(10000000) :\n",
        "            train_images_, train_labels_ = dataprovider.next_batch(batch_size)\n",
        "            _, acc_, loss_ = sess.run([train_op, acc, cee], feed_dict = {xs : train_images_,\n",
        "                                                                        ys : train_labels_})\n",
        "\n",
        "            if i% 1000 == 0 :\n",
        "                acc_vali , loss_vali = sess.run([acc, cee], feed_dict = {xs : test_images,\n",
        "                                                 ys : test_labels})\n",
        "                loss_list[i_bat].append(loss_vali)\n",
        "                acc_list[i_bat].append(acc_vali)\n",
        "                \n",
        "            if i % 10000 == 0:\n",
        "                print(\"iter :{}, val acc : {}, val loss : {}\". format(i, acc_, loss_))\n",
        "\n",
        "            if (i*batch_size) // 124800 == 20 :\n",
        "                print(\"**********20 epoch**********\")\n",
        "                break;\n"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch size : 1\n",
            "iter :0, val acc : 0.0, val loss : [3.4698443]\n",
            "iter :10000, val acc : 1.0, val loss : [2.5524302]\n",
            "iter :20000, val acc : 0.0, val loss : [3.3375332]\n",
            "iter :30000, val acc : 0.0, val loss : [3.7654908]\n",
            "iter :40000, val acc : 0.0, val loss : [2.1294868]\n",
            "iter :50000, val acc : 0.0, val loss : [3.1111064]\n",
            "iter :60000, val acc : 0.0, val loss : [3.1834233]\n",
            "iter :70000, val acc : 0.0, val loss : [3.1410718]\n",
            "iter :80000, val acc : 0.0, val loss : [3.0652688]\n",
            "iter :90000, val acc : 0.0, val loss : [3.0696843]\n",
            "iter :100000, val acc : 0.0, val loss : [2.495203]\n",
            "iter :110000, val acc : 0.0, val loss : [2.9520004]\n",
            "iter :120000, val acc : 0.0, val loss : [3.3151546]\n",
            "iter :130000, val acc : 0.0, val loss : [3.2776048]\n",
            "iter :140000, val acc : 0.0, val loss : [3.6013496]\n",
            "iter :150000, val acc : 0.0, val loss : [2.994816]\n",
            "iter :160000, val acc : 0.0, val loss : [3.1281507]\n",
            "iter :170000, val acc : 0.0, val loss : [2.932819]\n",
            "iter :180000, val acc : 0.0, val loss : [3.0901325]\n",
            "iter :190000, val acc : 0.0, val loss : [2.7973504]\n",
            "iter :200000, val acc : 0.0, val loss : [3.035593]\n",
            "iter :210000, val acc : 0.0, val loss : [3.2599304]\n",
            "iter :220000, val acc : 0.0, val loss : [3.1119149]\n",
            "iter :230000, val acc : 0.0, val loss : [3.1760454]\n",
            "iter :240000, val acc : 0.0, val loss : [3.3944514]\n",
            "iter :250000, val acc : 0.0, val loss : [3.5286374]\n",
            "iter :260000, val acc : 0.0, val loss : [3.3477297]\n",
            "iter :270000, val acc : 1.0, val loss : [2.9223242]\n",
            "iter :280000, val acc : 0.0, val loss : [3.2196054]\n",
            "iter :290000, val acc : 0.0, val loss : [3.0821443]\n",
            "iter :300000, val acc : 0.0, val loss : [3.3184812]\n",
            "iter :310000, val acc : 0.0, val loss : [3.275142]\n",
            "iter :320000, val acc : 0.0, val loss : [3.255804]\n",
            "iter :330000, val acc : 1.0, val loss : [2.8902872]\n",
            "iter :340000, val acc : 0.0, val loss : [3.0264726]\n",
            "iter :350000, val acc : 0.0, val loss : [3.176106]\n",
            "iter :360000, val acc : 0.0, val loss : [2.9724567]\n",
            "iter :370000, val acc : 0.0, val loss : [3.1636298]\n",
            "iter :380000, val acc : 0.0, val loss : [3.3932064]\n",
            "iter :390000, val acc : 0.0, val loss : [3.4304435]\n",
            "iter :400000, val acc : 0.0, val loss : [3.398132]\n",
            "iter :410000, val acc : 0.0, val loss : [3.5719006]\n",
            "iter :420000, val acc : 0.0, val loss : [2.9864647]\n",
            "iter :430000, val acc : 0.0, val loss : [3.5365314]\n",
            "iter :440000, val acc : 0.0, val loss : [3.0932848]\n",
            "iter :450000, val acc : 0.0, val loss : [3.1060407]\n",
            "iter :460000, val acc : 0.0, val loss : [3.1074967]\n",
            "iter :470000, val acc : 0.0, val loss : [3.2910695]\n",
            "iter :480000, val acc : 1.0, val loss : [2.7020636]\n",
            "iter :490000, val acc : 0.0, val loss : [3.1258426]\n",
            "iter :500000, val acc : 0.0, val loss : [3.682453]\n",
            "iter :510000, val acc : 0.0, val loss : [3.3888907]\n",
            "iter :520000, val acc : 0.0, val loss : [3.2454076]\n",
            "iter :530000, val acc : 0.0, val loss : [3.2355523]\n",
            "iter :540000, val acc : 0.0, val loss : [3.2891753]\n",
            "iter :550000, val acc : 0.0, val loss : [3.8352153]\n",
            "iter :560000, val acc : 0.0, val loss : [3.3065493]\n",
            "iter :570000, val acc : 0.0, val loss : [3.2559807]\n",
            "iter :580000, val acc : 0.0, val loss : [3.5680904]\n",
            "iter :590000, val acc : 0.0, val loss : [3.33498]\n",
            "iter :600000, val acc : 0.0, val loss : [3.4218936]\n",
            "iter :610000, val acc : 0.0, val loss : [3.228144]\n",
            "iter :620000, val acc : 1.0, val loss : [2.9455318]\n",
            "iter :630000, val acc : 0.0, val loss : [3.4344747]\n",
            "iter :640000, val acc : 0.0, val loss : [3.067381]\n",
            "iter :650000, val acc : 0.0, val loss : [3.2426138]\n",
            "iter :660000, val acc : 0.0, val loss : [3.0610473]\n",
            "iter :670000, val acc : 0.0, val loss : [3.551013]\n",
            "iter :680000, val acc : 0.0, val loss : [3.085665]\n",
            "iter :690000, val acc : 0.0, val loss : [3.268054]\n",
            "iter :700000, val acc : 0.0, val loss : [3.3823652]\n",
            "iter :710000, val acc : 0.0, val loss : [3.1500082]\n",
            "iter :720000, val acc : 0.0, val loss : [3.357712]\n",
            "iter :730000, val acc : 0.0, val loss : [3.292554]\n",
            "iter :740000, val acc : 0.0, val loss : [3.304083]\n",
            "iter :750000, val acc : 0.0, val loss : [3.1709409]\n",
            "iter :760000, val acc : 0.0, val loss : [3.3140593]\n",
            "iter :770000, val acc : 0.0, val loss : [3.379228]\n",
            "iter :780000, val acc : 0.0, val loss : [3.0542147]\n",
            "iter :790000, val acc : 0.0, val loss : [3.3579402]\n",
            "iter :800000, val acc : 0.0, val loss : [3.0176256]\n",
            "iter :810000, val acc : 0.0, val loss : [3.1999483]\n",
            "iter :820000, val acc : 0.0, val loss : [3.164386]\n",
            "iter :830000, val acc : 0.0, val loss : [3.2421901]\n",
            "iter :840000, val acc : 0.0, val loss : [3.1315718]\n",
            "iter :850000, val acc : 0.0, val loss : [3.4202323]\n",
            "iter :860000, val acc : 0.0, val loss : [3.240098]\n",
            "iter :870000, val acc : 0.0, val loss : [3.0733738]\n",
            "iter :880000, val acc : 0.0, val loss : [3.1909022]\n",
            "iter :890000, val acc : 0.0, val loss : [3.3752165]\n",
            "iter :900000, val acc : 0.0, val loss : [3.0714169]\n",
            "iter :910000, val acc : 0.0, val loss : [3.2214472]\n",
            "iter :920000, val acc : 1.0, val loss : [2.7175503]\n",
            "iter :930000, val acc : 0.0, val loss : [2.9609137]\n",
            "iter :940000, val acc : 0.0, val loss : [3.4181685]\n",
            "iter :950000, val acc : 0.0, val loss : [3.2128747]\n",
            "iter :960000, val acc : 0.0, val loss : [3.119813]\n",
            "iter :970000, val acc : 0.0, val loss : [3.2797847]\n",
            "iter :980000, val acc : 0.0, val loss : [3.4239979]\n",
            "iter :990000, val acc : 0.0, val loss : [3.3690705]\n",
            "iter :1000000, val acc : 0.0, val loss : [3.4022415]\n",
            "iter :1010000, val acc : 0.0, val loss : [3.2669392]\n",
            "iter :1020000, val acc : 0.0, val loss : [3.4127893]\n",
            "iter :1030000, val acc : 0.0, val loss : [3.156437]\n",
            "iter :1040000, val acc : 0.0, val loss : [3.2385018]\n",
            "iter :1050000, val acc : 0.0, val loss : [3.3519433]\n",
            "iter :1060000, val acc : 0.0, val loss : [3.2953591]\n",
            "iter :1070000, val acc : 0.0, val loss : [3.1828108]\n",
            "iter :1080000, val acc : 0.0, val loss : [3.7493014]\n",
            "iter :1090000, val acc : 0.0, val loss : [3.0535653]\n",
            "iter :1100000, val acc : 0.0, val loss : [3.1679072]\n",
            "iter :1110000, val acc : 0.0, val loss : [3.386507]\n",
            "iter :1120000, val acc : 0.0, val loss : [3.4594526]\n",
            "iter :1130000, val acc : 0.0, val loss : [3.3648486]\n",
            "iter :1140000, val acc : 0.0, val loss : [3.5149195]\n",
            "iter :1150000, val acc : 0.0, val loss : [3.0322251]\n",
            "iter :1160000, val acc : 0.0, val loss : [3.3568897]\n",
            "iter :1170000, val acc : 0.0, val loss : [3.027855]\n",
            "iter :1180000, val acc : 0.0, val loss : [3.4223332]\n",
            "iter :1190000, val acc : 0.0, val loss : [3.5216842]\n",
            "iter :1200000, val acc : 0.0, val loss : [3.3536773]\n",
            "iter :1210000, val acc : 0.0, val loss : [3.0779724]\n",
            "iter :1220000, val acc : 0.0, val loss : [3.2141163]\n",
            "iter :1230000, val acc : 0.0, val loss : [3.085658]\n",
            "iter :1240000, val acc : 0.0, val loss : [3.4040716]\n",
            "iter :1250000, val acc : 0.0, val loss : [3.2332819]\n",
            "iter :1260000, val acc : 0.0, val loss : [3.091437]\n",
            "iter :1270000, val acc : 0.0, val loss : [3.175892]\n",
            "iter :1280000, val acc : 0.0, val loss : [3.5288823]\n",
            "iter :1290000, val acc : 0.0, val loss : [3.2931414]\n",
            "iter :1300000, val acc : 0.0, val loss : [3.3538218]\n",
            "iter :1310000, val acc : 0.0, val loss : [3.1528034]\n",
            "iter :1320000, val acc : 0.0, val loss : [3.2472405]\n",
            "iter :1330000, val acc : 0.0, val loss : [3.2977946]\n",
            "iter :1340000, val acc : 0.0, val loss : [3.4533184]\n",
            "iter :1350000, val acc : 0.0, val loss : [3.4107666]\n",
            "iter :1360000, val acc : 0.0, val loss : [3.4798093]\n",
            "iter :1370000, val acc : 0.0, val loss : [3.2789648]\n",
            "iter :1380000, val acc : 0.0, val loss : [3.4277701]\n",
            "iter :1390000, val acc : 0.0, val loss : [3.1816876]\n",
            "iter :1400000, val acc : 1.0, val loss : [2.7381163]\n",
            "iter :1410000, val acc : 0.0, val loss : [3.1093073]\n",
            "iter :1420000, val acc : 0.0, val loss : [3.4758596]\n",
            "iter :1430000, val acc : 0.0, val loss : [3.1891525]\n",
            "iter :1440000, val acc : 0.0, val loss : [3.0856965]\n",
            "iter :1450000, val acc : 0.0, val loss : [3.0137784]\n",
            "iter :1460000, val acc : 0.0, val loss : [3.331684]\n",
            "iter :1470000, val acc : 0.0, val loss : [3.3605402]\n",
            "iter :1480000, val acc : 0.0, val loss : [3.463461]\n",
            "iter :1490000, val acc : 0.0, val loss : [3.254191]\n",
            "iter :1500000, val acc : 0.0, val loss : [3.142099]\n",
            "iter :1510000, val acc : 0.0, val loss : [3.361164]\n",
            "iter :1520000, val acc : 0.0, val loss : [3.5226135]\n",
            "iter :1530000, val acc : 0.0, val loss : [3.2038546]\n",
            "iter :1540000, val acc : 0.0, val loss : [3.2155437]\n",
            "iter :1550000, val acc : 0.0, val loss : [3.2636461]\n",
            "iter :1560000, val acc : 0.0, val loss : [3.0151167]\n",
            "iter :1570000, val acc : 0.0, val loss : [3.0269742]\n",
            "iter :1580000, val acc : 0.0, val loss : [3.4608796]\n",
            "iter :1590000, val acc : 0.0, val loss : [3.5272806]\n",
            "iter :1600000, val acc : 0.0, val loss : [3.0884662]\n",
            "iter :1610000, val acc : 0.0, val loss : [3.3660488]\n",
            "iter :1620000, val acc : 0.0, val loss : [3.1505375]\n",
            "iter :1630000, val acc : 0.0, val loss : [3.3277535]\n",
            "iter :1640000, val acc : 0.0, val loss : [3.1722505]\n",
            "iter :1650000, val acc : 0.0, val loss : [3.346445]\n",
            "iter :1660000, val acc : 0.0, val loss : [3.1665227]\n",
            "iter :1670000, val acc : 0.0, val loss : [3.2697463]\n",
            "iter :1680000, val acc : 0.0, val loss : [3.4521081]\n",
            "iter :1690000, val acc : 0.0, val loss : [3.2364464]\n",
            "iter :1700000, val acc : 0.0, val loss : [2.8096414]\n",
            "iter :1710000, val acc : 0.0, val loss : [3.06646]\n",
            "iter :1720000, val acc : 0.0, val loss : [2.88063]\n",
            "iter :1730000, val acc : 0.0, val loss : [3.110597]\n",
            "iter :1740000, val acc : 0.0, val loss : [3.414937]\n",
            "iter :1750000, val acc : 0.0, val loss : [3.029953]\n",
            "iter :1760000, val acc : 0.0, val loss : [3.4022055]\n",
            "iter :1770000, val acc : 0.0, val loss : [3.1762671]\n",
            "iter :1780000, val acc : 0.0, val loss : [3.4614234]\n",
            "iter :1790000, val acc : 0.0, val loss : [3.034377]\n",
            "iter :1800000, val acc : 0.0, val loss : [2.9287958]\n",
            "iter :1810000, val acc : 0.0, val loss : [3.304694]\n",
            "iter :1820000, val acc : 0.0, val loss : [3.248959]\n",
            "iter :1830000, val acc : 0.0, val loss : [3.2109966]\n",
            "iter :1840000, val acc : 0.0, val loss : [3.1570442]\n",
            "iter :1850000, val acc : 0.0, val loss : [3.7253692]\n",
            "iter :1860000, val acc : 0.0, val loss : [3.1203425]\n",
            "iter :1870000, val acc : 0.0, val loss : [3.301841]\n",
            "iter :1880000, val acc : 0.0, val loss : [3.0294359]\n",
            "iter :1890000, val acc : 0.0, val loss : [3.319386]\n",
            "iter :1900000, val acc : 0.0, val loss : [2.9864075]\n",
            "iter :1910000, val acc : 0.0, val loss : [3.4028256]\n",
            "iter :1920000, val acc : 0.0, val loss : [3.198045]\n",
            "iter :1930000, val acc : 0.0, val loss : [3.455092]\n",
            "iter :1940000, val acc : 0.0, val loss : [3.5235999]\n",
            "iter :1950000, val acc : 0.0, val loss : [3.324089]\n",
            "iter :1960000, val acc : 0.0, val loss : [3.34713]\n",
            "iter :1970000, val acc : 1.0, val loss : [2.9746182]\n",
            "iter :1980000, val acc : 0.0, val loss : [3.5531058]\n",
            "iter :1990000, val acc : 0.0, val loss : [3.181094]\n",
            "iter :2000000, val acc : 0.0, val loss : [3.007732]\n",
            "iter :2010000, val acc : 0.0, val loss : [3.4231842]\n",
            "iter :2020000, val acc : 0.0, val loss : [3.5109718]\n",
            "iter :2030000, val acc : 0.0, val loss : [3.402298]\n",
            "iter :2040000, val acc : 0.0, val loss : [3.2195835]\n",
            "iter :2050000, val acc : 0.0, val loss : [3.1342616]\n",
            "iter :2060000, val acc : 0.0, val loss : [3.4958107]\n",
            "iter :2070000, val acc : 0.0, val loss : [3.4045916]\n",
            "iter :2080000, val acc : 0.0, val loss : [3.4741383]\n",
            "iter :2090000, val acc : 0.0, val loss : [3.2573504]\n",
            "iter :2100000, val acc : 0.0, val loss : [3.5438766]\n",
            "iter :2110000, val acc : 0.0, val loss : [3.333468]\n",
            "iter :2120000, val acc : 0.0, val loss : [3.7085555]\n",
            "iter :2130000, val acc : 0.0, val loss : [3.4192138]\n",
            "iter :2140000, val acc : 0.0, val loss : [3.3274176]\n",
            "iter :2150000, val acc : 0.0, val loss : [3.1665976]\n",
            "iter :2160000, val acc : 0.0, val loss : [3.5137992]\n",
            "iter :2170000, val acc : 0.0, val loss : [2.8159428]\n",
            "iter :2180000, val acc : 0.0, val loss : [3.3331752]\n",
            "iter :2190000, val acc : 0.0, val loss : [3.3649654]\n",
            "iter :2200000, val acc : 0.0, val loss : [3.49351]\n",
            "iter :2210000, val acc : 1.0, val loss : [2.8132467]\n",
            "iter :2220000, val acc : 0.0, val loss : [3.0707622]\n",
            "iter :2230000, val acc : 0.0, val loss : [3.1714864]\n",
            "iter :2240000, val acc : 0.0, val loss : [3.320534]\n",
            "iter :2250000, val acc : 0.0, val loss : [3.2769914]\n",
            "iter :2260000, val acc : 0.0, val loss : [3.3995843]\n",
            "iter :2270000, val acc : 0.0, val loss : [3.5926385]\n",
            "iter :2280000, val acc : 0.0, val loss : [3.4007397]\n",
            "iter :2290000, val acc : 0.0, val loss : [3.4471636]\n",
            "iter :2300000, val acc : 0.0, val loss : [3.122278]\n",
            "iter :2310000, val acc : 0.0, val loss : [3.527448]\n",
            "iter :2320000, val acc : 0.0, val loss : [2.9913151]\n",
            "iter :2330000, val acc : 0.0, val loss : [3.1171825]\n",
            "iter :2340000, val acc : 0.0, val loss : [3.304369]\n",
            "iter :2350000, val acc : 0.0, val loss : [3.0303288]\n",
            "iter :2360000, val acc : 0.0, val loss : [3.3624246]\n",
            "iter :2370000, val acc : 0.0, val loss : [3.1425216]\n",
            "iter :2380000, val acc : 0.0, val loss : [3.2327354]\n",
            "iter :2390000, val acc : 0.0, val loss : [3.5073135]\n",
            "iter :2400000, val acc : 0.0, val loss : [3.3242185]\n",
            "iter :2410000, val acc : 0.0, val loss : [3.0120308]\n",
            "iter :2420000, val acc : 0.0, val loss : [3.381965]\n",
            "iter :2430000, val acc : 0.0, val loss : [3.2932558]\n",
            "iter :2440000, val acc : 0.0, val loss : [3.4901192]\n",
            "iter :2450000, val acc : 0.0, val loss : [3.3411136]\n",
            "iter :2460000, val acc : 0.0, val loss : [2.9857702]\n",
            "iter :2470000, val acc : 0.0, val loss : [3.2776058]\n",
            "iter :2480000, val acc : 0.0, val loss : [3.4271586]\n",
            "iter :2490000, val acc : 0.0, val loss : [3.4795237]\n",
            "**********20 epoch**********\n",
            "batch size : 10\n",
            "iter :0, val acc : 0.0, val loss : [3.4094958]\n",
            "iter :10000, val acc : 0.8999999761581421, val loss : [0.60177004]\n",
            "iter :20000, val acc : 1.0, val loss : [0.051226407]\n",
            "iter :30000, val acc : 0.8999999761581421, val loss : [0.36316913]\n",
            "iter :40000, val acc : 0.800000011920929, val loss : [0.43413305]\n",
            "iter :50000, val acc : 0.8999999761581421, val loss : [0.26647282]\n",
            "iter :60000, val acc : 0.699999988079071, val loss : [0.78790724]\n",
            "iter :70000, val acc : 0.8999999761581421, val loss : [0.3938726]\n",
            "iter :80000, val acc : 1.0, val loss : [0.3090025]\n",
            "iter :90000, val acc : 0.800000011920929, val loss : [1.546196]\n",
            "iter :100000, val acc : 0.699999988079071, val loss : [0.486019]\n",
            "iter :110000, val acc : 0.8999999761581421, val loss : [0.2086273]\n",
            "iter :120000, val acc : 1.0, val loss : [0.15442814]\n",
            "iter :130000, val acc : 0.8999999761581421, val loss : [0.6853864]\n",
            "iter :140000, val acc : 0.699999988079071, val loss : [0.9288244]\n",
            "iter :150000, val acc : 0.800000011920929, val loss : [0.3338905]\n",
            "iter :160000, val acc : 0.8999999761581421, val loss : [0.53957856]\n",
            "iter :170000, val acc : 1.0, val loss : [0.11472757]\n",
            "iter :180000, val acc : 0.800000011920929, val loss : [0.8869052]\n",
            "iter :190000, val acc : 0.699999988079071, val loss : [0.6488019]\n",
            "iter :200000, val acc : 0.8999999761581421, val loss : [0.20189622]\n",
            "iter :210000, val acc : 0.8999999761581421, val loss : [0.29386458]\n",
            "iter :220000, val acc : 0.800000011920929, val loss : [0.5431732]\n",
            "iter :230000, val acc : 0.800000011920929, val loss : [0.7987092]\n",
            "iter :240000, val acc : 0.8999999761581421, val loss : [0.6212797]\n",
            "**********20 epoch**********\n",
            "batch size : 60\n",
            "iter :0, val acc : 0.01666666753590107, val loss : [3.3548074]\n",
            "iter :10000, val acc : 0.8999999761581421, val loss : [0.32606298]\n",
            "iter :20000, val acc : 0.9833333492279053, val loss : [0.094817884]\n",
            "iter :30000, val acc : 0.949999988079071, val loss : [0.114299275]\n",
            "iter :40000, val acc : 0.9333333373069763, val loss : [0.15794198]\n",
            "**********20 epoch**********\n",
            "batch size : 120\n",
            "iter :0, val acc : 0.02500000037252903, val loss : [3.3514137]\n",
            "iter :10000, val acc : 0.9333333373069763, val loss : [0.22589011]\n",
            "iter :20000, val acc : 0.949999988079071, val loss : [0.1444703]\n",
            "**********20 epoch**********\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G3rhOy1Caf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "0e0f344d-f6e8-408c-ef11-3486b8c5e763"
      },
      "source": [
        "fig = plt.figure(figsize = (10,5))\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "for bat in range(len(batch_sizes[1:])) :\n",
        "    ax1.plot(loss_list[bat+1])\n",
        "    ax2.plot(acc_list[bat+1])"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAEyCAYAAAA4KJ7OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkAkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3NffzmRRsnPo"
      },
      "source": [
        "### 정답 확인 : \n",
        "\n",
        "- batch size 을 1, 10, 60, 100 로 했을때 validation accuracy, loss graph 을 그려봅니다.\n",
        "\n",
        "아래와 같은 모양이 나오면 정답입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KeuLaxpYClez"
      },
      "source": [
        "![Imgur](https://i.imgur.com/2CXUDqC.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3IzIVKHoYgiV"
      },
      "source": [
        "#  \n",
        "\n",
        "<hr>\n",
        "<div style = \"background-image: url('https://algorithmai.io/static/media/logo.665798c4.png');background-repeat: no-repeat; background-position: right; background-size: 220px 40px; padding : 5px 10px 5px 5px;\">\n",
        "    Copyright(c) 2019 by Public AI. All rights reserved.<br>\n",
        "    Writen by PAI, SangJae Kang ( rocketgrowthsj@publicai.co.kr )  last updated on 2019/04/17\n",
        "</div>\n",
        "<hr>"
      ]
    }
  ]
}